{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding the title and query into vector space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('data/final_data.csv')\n",
    "data_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "data_df['abstract'] = data_df['abstract'].astype(str)\n",
    "data_df['title'] = data_df['title'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>rank_gs</th>\n",
       "      <th>title</th>\n",
       "      <th>rate_gs</th>\n",
       "      <th>rank_pc</th>\n",
       "      <th>rate_pc</th>\n",
       "      <th>rank_ss</th>\n",
       "      <th>rate_ss</th>\n",
       "      <th>agg_rate</th>\n",
       "      <th>agg_rank</th>\n",
       "      <th>rank</th>\n",
       "      <th>pdf_link</th>\n",
       "      <th>abstract</th>\n",
       "      <th>file_name</th>\n",
       "      <th>citationCount</th>\n",
       "      <th>referenceCount</th>\n",
       "      <th>influentialCitationCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D Reconstruction</td>\n",
       "      <td>9.0</td>\n",
       "      <td>occupancy networks: learning 3d reconstruction...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1</td>\n",
       "      <td>http://openaccess.thecvf.com/content_CVPR_2019...</td>\n",
       "      <td>With the advent of deep neural networks, learn...</td>\n",
       "      <td>3ocnele3dreinfusp</td>\n",
       "      <td>623.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3D Reconstruction</td>\n",
       "      <td>68.0</td>\n",
       "      <td>weakly supervised 3d reconstruction with adver...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>30.7</td>\n",
       "      <td>2</td>\n",
       "      <td>https://arxiv.org/pdf/1705.10904</td>\n",
       "      <td>Supervised 3D reconstruction has witnessed a s...</td>\n",
       "      <td>3wesu3drewiadco</td>\n",
       "      <td>85.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3D Reconstruction</td>\n",
       "      <td>95.0</td>\n",
       "      <td>infinitam v3: a framework for large-scale 3d r...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>44.9</td>\n",
       "      <td>3</td>\n",
       "      <td>https://arxiv.org/pdf/1708.00783</td>\n",
       "      <td>Volumetric models have become a popular repres...</td>\n",
       "      <td>3inv3afrfola3drewilocl</td>\n",
       "      <td>59.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3D Reconstruction</td>\n",
       "      <td>30.0</td>\n",
       "      <td>pix2vox: context-aware 3d reconstruction from ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>28.5</td>\n",
       "      <td>4</td>\n",
       "      <td>http://openaccess.thecvf.com/content_ICCV_2019...</td>\n",
       "      <td>Recovering the 3D representation of an object ...</td>\n",
       "      <td>3pico3drefrsianmuim</td>\n",
       "      <td>70.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3D Reconstruction</td>\n",
       "      <td>33.0</td>\n",
       "      <td>image2mesh: a learning framework for single im...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5</td>\n",
       "      <td>https://arxiv.org/pdf/1711.10669</td>\n",
       "      <td>One challenge that remains open in 3D deep lea...</td>\n",
       "      <td>3imalefrfosiim3dre</td>\n",
       "      <td>70.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                area  rank_gs  \\\n",
       "0  3D Reconstruction      9.0   \n",
       "1  3D Reconstruction     68.0   \n",
       "2  3D Reconstruction     95.0   \n",
       "3  3D Reconstruction     30.0   \n",
       "4  3D Reconstruction     33.0   \n",
       "\n",
       "                                               title  rate_gs  rank_pc  \\\n",
       "0  occupancy networks: learning 3d reconstruction...      5.0     18.0   \n",
       "1  weakly supervised 3d reconstruction with adver...      4.0      4.0   \n",
       "2  infinitam v3: a framework for large-scale 3d r...      4.0     17.0   \n",
       "3  pix2vox: context-aware 3d reconstruction from ...      5.0     45.0   \n",
       "4  image2mesh: a learning framework for single im...      5.0     94.0   \n",
       "\n",
       "   rate_pc  rank_ss  rate_ss  agg_rate  agg_rank  rank  \\\n",
       "0      5.0      1.0      5.0       5.0      10.2     1   \n",
       "1      5.0     29.0      5.0       4.7      30.7     2   \n",
       "2      5.0     32.0      5.0       4.7      44.9     3   \n",
       "3      4.0      5.0      5.0       4.6      28.5     4   \n",
       "4      4.0     15.0      5.0       4.6      52.0     5   \n",
       "\n",
       "                                            pdf_link  \\\n",
       "0  http://openaccess.thecvf.com/content_CVPR_2019...   \n",
       "1                   https://arxiv.org/pdf/1705.10904   \n",
       "2                   https://arxiv.org/pdf/1708.00783   \n",
       "3  http://openaccess.thecvf.com/content_ICCV_2019...   \n",
       "4                   https://arxiv.org/pdf/1711.10669   \n",
       "\n",
       "                                            abstract               file_name  \\\n",
       "0  With the advent of deep neural networks, learn...       3ocnele3dreinfusp   \n",
       "1  Supervised 3D reconstruction has witnessed a s...         3wesu3drewiadco   \n",
       "2  Volumetric models have become a popular repres...  3inv3afrfola3drewilocl   \n",
       "3  Recovering the 3D representation of an object ...     3pico3drefrsianmuim   \n",
       "4  One challenge that remains open in 3D deep lea...      3imalefrfosiim3dre   \n",
       "\n",
       "   citationCount  referenceCount  influentialCitationCount  \n",
       "0          623.0            86.0                     136.0  \n",
       "1           85.0            60.0                       3.0  \n",
       "2           59.0            13.0                       6.0  \n",
       "3           70.0            49.0                       8.0  \n",
       "4           70.0            53.0                       3.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_info = data_df[['title', 'abstract']].copy()\n",
    "text_info['text'] = text_info['title'] + '\\n' + text_info['abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>occupancy networks: learning 3d reconstruction...</td>\n",
       "      <td>With the advent of deep neural networks, learn...</td>\n",
       "      <td>occupancy networks: learning 3d reconstruction...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weakly supervised 3d reconstruction with adver...</td>\n",
       "      <td>Supervised 3D reconstruction has witnessed a s...</td>\n",
       "      <td>weakly supervised 3d reconstruction with adver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>infinitam v3: a framework for large-scale 3d r...</td>\n",
       "      <td>Volumetric models have become a popular repres...</td>\n",
       "      <td>infinitam v3: a framework for large-scale 3d r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pix2vox: context-aware 3d reconstruction from ...</td>\n",
       "      <td>Recovering the 3D representation of an object ...</td>\n",
       "      <td>pix2vox: context-aware 3d reconstruction from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image2mesh: a learning framework for single im...</td>\n",
       "      <td>One challenge that remains open in 3D deep lea...</td>\n",
       "      <td>image2mesh: a learning framework for single im...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  occupancy networks: learning 3d reconstruction...   \n",
       "1  weakly supervised 3d reconstruction with adver...   \n",
       "2  infinitam v3: a framework for large-scale 3d r...   \n",
       "3  pix2vox: context-aware 3d reconstruction from ...   \n",
       "4  image2mesh: a learning framework for single im...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  With the advent of deep neural networks, learn...   \n",
       "1  Supervised 3D reconstruction has witnessed a s...   \n",
       "2  Volumetric models have become a popular repres...   \n",
       "3  Recovering the 3D representation of an object ...   \n",
       "4  One challenge that remains open in 3D deep lea...   \n",
       "\n",
       "                                                text  \n",
       "0  occupancy networks: learning 3d reconstruction...  \n",
       "1  weakly supervised 3d reconstruction with adver...  \n",
       "2  infinitam v3: a framework for large-scale 3d r...  \n",
       "3  pix2vox: context-aware 3d reconstruction from ...  \n",
       "4  image2mesh: a learning framework for single im...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8255/8255 [02:56<00:00, 46.72it/s]\n"
     ]
    }
   ],
   "source": [
    "title_embeddings = []\n",
    "for title in tqdm(text_info['title']):\n",
    "    title_embeddings.append(model.encode(title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8255/8255 [02:41<00:00, 51.16it/s]\n"
     ]
    }
   ],
   "source": [
    "abstract_embeddings = []\n",
    "for abstract in tqdm(text_info['abstract']):\n",
    "    abstract_embeddings.append(model.encode('abstract'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8255/8255 [06:42<00:00, 20.50it/s]\n"
     ]
    }
   ],
   "source": [
    "total_embeddings = []\n",
    "for total in tqdm(text_info['text']):\n",
    "    total_embeddings.append(model.encode(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['title_embeddings'] = title_embeddings\n",
    "data_df['abstract_embeddings'] = abstract_embeddings\n",
    "data_df['total_embeddings'] = total_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_pickle('data/data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_pickle('data/data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = data_df[['area','title_embeddings', 'abstract_embeddings', 'total_embeddings']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_df = temp_df.groupby('area').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_dict = {area: centroid_df.loc[area, ['title_embeddings', 'abstract_embeddings', 'total_embeddings']].tolist() for area in centroid_df.index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_df.to_pickle('data/centroids.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('data/centroids_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(centroid_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create PT indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyterrier as pt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not pt.started():\n",
    "    pt.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_dir = './data/index'\n",
    "indexer = pt.DFIndexer(index_dir, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_pickle('data/data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>rank_gs</th>\n",
       "      <th>title</th>\n",
       "      <th>rate_gs</th>\n",
       "      <th>rank_pc</th>\n",
       "      <th>rate_pc</th>\n",
       "      <th>rank_ss</th>\n",
       "      <th>rate_ss</th>\n",
       "      <th>agg_rate</th>\n",
       "      <th>agg_rank</th>\n",
       "      <th>rank</th>\n",
       "      <th>pdf_link</th>\n",
       "      <th>abstract</th>\n",
       "      <th>file_name</th>\n",
       "      <th>citationCount</th>\n",
       "      <th>referenceCount</th>\n",
       "      <th>influentialCitationCount</th>\n",
       "      <th>title_embeddings</th>\n",
       "      <th>abstract_embeddings</th>\n",
       "      <th>total_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D Reconstruction</td>\n",
       "      <td>9.0</td>\n",
       "      <td>occupancy networks: learning 3d reconstruction...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1</td>\n",
       "      <td>http://openaccess.thecvf.com/content_CVPR_2019...</td>\n",
       "      <td>With the advent of deep neural networks, learn...</td>\n",
       "      <td>3ocnele3dreinfusp</td>\n",
       "      <td>623.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>[-0.05088244, 0.053124595, 0.0023723403, 0.022...</td>\n",
       "      <td>[0.012619468, 0.06828206, -0.0018017464, 0.002...</td>\n",
       "      <td>[-0.060328517, 0.06280401, 0.026933515, 0.0345...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3D Reconstruction</td>\n",
       "      <td>68.0</td>\n",
       "      <td>weakly supervised 3d reconstruction with adver...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>30.7</td>\n",
       "      <td>2</td>\n",
       "      <td>https://arxiv.org/pdf/1705.10904</td>\n",
       "      <td>Supervised 3D reconstruction has witnessed a s...</td>\n",
       "      <td>3wesu3drewiadco</td>\n",
       "      <td>85.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[0.041443087, 0.09971384, 0.034612227, 0.05238...</td>\n",
       "      <td>[0.012619468, 0.06828206, -0.0018017464, 0.002...</td>\n",
       "      <td>[-0.014805883, 0.093130484, 0.03753042, 0.0462...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3D Reconstruction</td>\n",
       "      <td>95.0</td>\n",
       "      <td>infinitam v3: a framework for large-scale 3d r...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>44.9</td>\n",
       "      <td>3</td>\n",
       "      <td>https://arxiv.org/pdf/1708.00783</td>\n",
       "      <td>Volumetric models have become a popular repres...</td>\n",
       "      <td>3inv3afrfola3drewilocl</td>\n",
       "      <td>59.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[-0.027944634, 0.058888804, 0.016118925, 0.007...</td>\n",
       "      <td>[0.012619468, 0.06828206, -0.0018017464, 0.002...</td>\n",
       "      <td>[0.007331516, -0.0009151098, 0.054103583, 0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3D Reconstruction</td>\n",
       "      <td>30.0</td>\n",
       "      <td>pix2vox: context-aware 3d reconstruction from ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>28.5</td>\n",
       "      <td>4</td>\n",
       "      <td>http://openaccess.thecvf.com/content_ICCV_2019...</td>\n",
       "      <td>Recovering the 3D representation of an object ...</td>\n",
       "      <td>3pico3drefrsianmuim</td>\n",
       "      <td>70.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[-0.03636022, 0.038363226, 0.06699201, 0.05293...</td>\n",
       "      <td>[0.012619468, 0.06828206, -0.0018017464, 0.002...</td>\n",
       "      <td>[-0.021163054, 0.089947246, 0.057269774, 0.069...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3D Reconstruction</td>\n",
       "      <td>33.0</td>\n",
       "      <td>image2mesh: a learning framework for single im...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5</td>\n",
       "      <td>https://arxiv.org/pdf/1711.10669</td>\n",
       "      <td>One challenge that remains open in 3D deep lea...</td>\n",
       "      <td>3imalefrfosiim3dre</td>\n",
       "      <td>70.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[-0.046021443, 0.087248586, 0.038778853, 0.037...</td>\n",
       "      <td>[0.012619468, 0.06828206, -0.0018017464, 0.002...</td>\n",
       "      <td>[-0.08701608, 0.06889409, 0.028026856, 0.01509...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                area  rank_gs  \\\n",
       "0  3D Reconstruction      9.0   \n",
       "1  3D Reconstruction     68.0   \n",
       "2  3D Reconstruction     95.0   \n",
       "3  3D Reconstruction     30.0   \n",
       "4  3D Reconstruction     33.0   \n",
       "\n",
       "                                               title  rate_gs  rank_pc  \\\n",
       "0  occupancy networks: learning 3d reconstruction...      5.0     18.0   \n",
       "1  weakly supervised 3d reconstruction with adver...      4.0      4.0   \n",
       "2  infinitam v3: a framework for large-scale 3d r...      4.0     17.0   \n",
       "3  pix2vox: context-aware 3d reconstruction from ...      5.0     45.0   \n",
       "4  image2mesh: a learning framework for single im...      5.0     94.0   \n",
       "\n",
       "   rate_pc  rank_ss  rate_ss  agg_rate  agg_rank  rank  \\\n",
       "0      5.0      1.0      5.0       5.0      10.2     1   \n",
       "1      5.0     29.0      5.0       4.7      30.7     2   \n",
       "2      5.0     32.0      5.0       4.7      44.9     3   \n",
       "3      4.0      5.0      5.0       4.6      28.5     4   \n",
       "4      4.0     15.0      5.0       4.6      52.0     5   \n",
       "\n",
       "                                            pdf_link  \\\n",
       "0  http://openaccess.thecvf.com/content_CVPR_2019...   \n",
       "1                   https://arxiv.org/pdf/1705.10904   \n",
       "2                   https://arxiv.org/pdf/1708.00783   \n",
       "3  http://openaccess.thecvf.com/content_ICCV_2019...   \n",
       "4                   https://arxiv.org/pdf/1711.10669   \n",
       "\n",
       "                                            abstract               file_name  \\\n",
       "0  With the advent of deep neural networks, learn...       3ocnele3dreinfusp   \n",
       "1  Supervised 3D reconstruction has witnessed a s...         3wesu3drewiadco   \n",
       "2  Volumetric models have become a popular repres...  3inv3afrfola3drewilocl   \n",
       "3  Recovering the 3D representation of an object ...     3pico3drefrsianmuim   \n",
       "4  One challenge that remains open in 3D deep lea...      3imalefrfosiim3dre   \n",
       "\n",
       "   citationCount  referenceCount  influentialCitationCount  \\\n",
       "0          623.0            86.0                     136.0   \n",
       "1           85.0            60.0                       3.0   \n",
       "2           59.0            13.0                       6.0   \n",
       "3           70.0            49.0                       8.0   \n",
       "4           70.0            53.0                       3.0   \n",
       "\n",
       "                                    title_embeddings  \\\n",
       "0  [-0.05088244, 0.053124595, 0.0023723403, 0.022...   \n",
       "1  [0.041443087, 0.09971384, 0.034612227, 0.05238...   \n",
       "2  [-0.027944634, 0.058888804, 0.016118925, 0.007...   \n",
       "3  [-0.03636022, 0.038363226, 0.06699201, 0.05293...   \n",
       "4  [-0.046021443, 0.087248586, 0.038778853, 0.037...   \n",
       "\n",
       "                                 abstract_embeddings  \\\n",
       "0  [0.012619468, 0.06828206, -0.0018017464, 0.002...   \n",
       "1  [0.012619468, 0.06828206, -0.0018017464, 0.002...   \n",
       "2  [0.012619468, 0.06828206, -0.0018017464, 0.002...   \n",
       "3  [0.012619468, 0.06828206, -0.0018017464, 0.002...   \n",
       "4  [0.012619468, 0.06828206, -0.0018017464, 0.002...   \n",
       "\n",
       "                                    total_embeddings  \n",
       "0  [-0.060328517, 0.06280401, 0.026933515, 0.0345...  \n",
       "1  [-0.014805883, 0.093130484, 0.03753042, 0.0462...  \n",
       "2  [0.007331516, -0.0009151098, 0.054103583, 0.03...  \n",
       "3  [-0.021163054, 0.089947246, 0.057269774, 0.069...  \n",
       "4  [-0.08701608, 0.06889409, 0.028026856, 0.01509...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = data_df[['title', 'abstract', 'title_embeddings', 'abstract_embeddings', 'area', 'total_embeddings']].copy()\n",
    "papers = papers.groupby(['title']).agg({'title': 'first', 'abstract': 'first', 'title_embeddings': 'first', 'abstract_embeddings': 'first', 'area': ','.join}).reset_index(drop=True)\n",
    "# papers = papers.drop_duplicates(subset=['title']).reset_index(drop=True)\n",
    "papers['docno'] = papers.index.to_series().apply(lambda x: str(x))\n",
    "papers.rename(columns={'abstract': 'text'}, inplace=True)\n",
    "papers['text'] = papers['text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>title_embeddings</th>\n",
       "      <th>abstract_embeddings</th>\n",
       "      <th>area</th>\n",
       "      <th>docno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"zero-shot\" super-resolution using deep intern...</td>\n",
       "      <td>Generative adversarial networks (GANs) are amo...</td>\n",
       "      <td>[-0.07775616, 0.05288399, 0.03650218, 0.038884...</td>\n",
       "      <td>[0.012619468, 0.06828206, -0.0018017464, 0.002...</td>\n",
       "      <td>Image Compression,Super-Resolution</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(blockchain technology and industry 4.0 at aut...</td>\n",
       "      <td>Through a literature review, this paper aims t...</td>\n",
       "      <td>[-0.020874746, 0.028415756, -0.016895752, 0.05...</td>\n",
       "      <td>[0.012619468, 0.06828206, -0.0018017464, 0.002...</td>\n",
       "      <td>Autonomous vehicles</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(male, bachelor) and (female, ph.d) have diffe...</td>\n",
       "      <td>Stylistic variation in text needs to be studie...</td>\n",
       "      <td>[0.05497964, 0.056969024, -0.04139412, 0.01792...</td>\n",
       "      <td>[0.012619468, 0.06828206, -0.0018017464, 0.002...</td>\n",
       "      <td>Style Transfer</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>124-color super-resolution imaging by engineer...</td>\n",
       "      <td>Optical super-resolution techniques reach unpr...</td>\n",
       "      <td>[0.0032263368, 0.015332368, -0.0021535154, -0....</td>\n",
       "      <td>[0.012619468, 0.06828206, -0.0018017464, 0.002...</td>\n",
       "      <td>Super-Resolution</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1st place solution for ava-kinetics crossover ...</td>\n",
       "      <td>This technical report introduces our winning s...</td>\n",
       "      <td>[-0.06893435, -0.011644914, -0.035723064, 0.04...</td>\n",
       "      <td>[0.012619468, 0.06828206, -0.0018017464, 0.002...</td>\n",
       "      <td>Action Recognition</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  \"zero-shot\" super-resolution using deep intern...   \n",
       "1  (blockchain technology and industry 4.0 at aut...   \n",
       "2  (male, bachelor) and (female, ph.d) have diffe...   \n",
       "3  124-color super-resolution imaging by engineer...   \n",
       "4  1st place solution for ava-kinetics crossover ...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Generative adversarial networks (GANs) are amo...   \n",
       "1  Through a literature review, this paper aims t...   \n",
       "2  Stylistic variation in text needs to be studie...   \n",
       "3  Optical super-resolution techniques reach unpr...   \n",
       "4  This technical report introduces our winning s...   \n",
       "\n",
       "                                    title_embeddings  \\\n",
       "0  [-0.07775616, 0.05288399, 0.03650218, 0.038884...   \n",
       "1  [-0.020874746, 0.028415756, -0.016895752, 0.05...   \n",
       "2  [0.05497964, 0.056969024, -0.04139412, 0.01792...   \n",
       "3  [0.0032263368, 0.015332368, -0.0021535154, -0....   \n",
       "4  [-0.06893435, -0.011644914, -0.035723064, 0.04...   \n",
       "\n",
       "                                 abstract_embeddings  \\\n",
       "0  [0.012619468, 0.06828206, -0.0018017464, 0.002...   \n",
       "1  [0.012619468, 0.06828206, -0.0018017464, 0.002...   \n",
       "2  [0.012619468, 0.06828206, -0.0018017464, 0.002...   \n",
       "3  [0.012619468, 0.06828206, -0.0018017464, 0.002...   \n",
       "4  [0.012619468, 0.06828206, -0.0018017464, 0.002...   \n",
       "\n",
       "                                 area docno  \n",
       "0  Image Compression,Super-Resolution     0  \n",
       "1                 Autonomous vehicles     1  \n",
       "2                      Style Transfer     2  \n",
       "3                    Super-Resolution     3  \n",
       "4                  Action Recognition     4  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexref = indexer.index(papers['text'], papers['docno'], papers['title'], papers['area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers[['docno', 'title_embeddings', 'abstract_embeddings']].to_pickle('data/paper_embeddings.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_info_df = data_df[['title', 'area', 'rank_gs', 'rate_gs', 'rank_pc', 'rate_pc', 'rank_ss',\n",
    "       'rate_ss', 'agg_rate', 'agg_rank', 'rank', 'citationCount', 'referenceCount',\n",
    "       'influentialCitationCount']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_dict = {docno: title for docno, title in zip(papers['docno'].to_list(), papers['title'].to_list())}\n",
    "with open ('data/ref_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(ref_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_info_df = extra_info_df.merge(papers[['docno', 'title']], on='title', how='left')\n",
    "extra_info_df.drop(columns=['title'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>area</th>\n",
       "      <th>rank_gs</th>\n",
       "      <th>rate_gs</th>\n",
       "      <th>rank_pc</th>\n",
       "      <th>rate_pc</th>\n",
       "      <th>rank_ss</th>\n",
       "      <th>rate_ss</th>\n",
       "      <th>agg_rate</th>\n",
       "      <th>agg_rank</th>\n",
       "      <th>rank</th>\n",
       "      <th>citationCount</th>\n",
       "      <th>referenceCount</th>\n",
       "      <th>influentialCitationCount</th>\n",
       "      <th>docno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>occupancy networks: learning 3d reconstruction...</td>\n",
       "      <td>3D Reconstruction</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1</td>\n",
       "      <td>623.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>5295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weakly supervised 3d reconstruction with adver...</td>\n",
       "      <td>3D Reconstruction</td>\n",
       "      <td>68.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>30.7</td>\n",
       "      <td>2</td>\n",
       "      <td>85.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>infinitam v3: a framework for large-scale 3d r...</td>\n",
       "      <td>3D Reconstruction</td>\n",
       "      <td>95.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>44.9</td>\n",
       "      <td>3</td>\n",
       "      <td>59.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pix2vox: context-aware 3d reconstruction from ...</td>\n",
       "      <td>3D Reconstruction</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>28.5</td>\n",
       "      <td>4</td>\n",
       "      <td>70.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image2mesh: a learning framework for single im...</td>\n",
       "      <td>3D Reconstruction</td>\n",
       "      <td>33.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5</td>\n",
       "      <td>70.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title               area  \\\n",
       "0  occupancy networks: learning 3d reconstruction...  3D Reconstruction   \n",
       "1  weakly supervised 3d reconstruction with adver...  3D Reconstruction   \n",
       "2  infinitam v3: a framework for large-scale 3d r...  3D Reconstruction   \n",
       "3  pix2vox: context-aware 3d reconstruction from ...  3D Reconstruction   \n",
       "4  image2mesh: a learning framework for single im...  3D Reconstruction   \n",
       "\n",
       "   rank_gs  rate_gs  rank_pc  rate_pc  rank_ss  rate_ss  agg_rate  agg_rank  \\\n",
       "0      9.0      5.0     18.0      5.0      1.0      5.0       5.0      10.2   \n",
       "1     68.0      4.0      4.0      5.0     29.0      5.0       4.7      30.7   \n",
       "2     95.0      4.0     17.0      5.0     32.0      5.0       4.7      44.9   \n",
       "3     30.0      5.0     45.0      4.0      5.0      5.0       4.6      28.5   \n",
       "4     33.0      5.0     94.0      4.0     15.0      5.0       4.6      52.0   \n",
       "\n",
       "   rank  citationCount  referenceCount  influentialCitationCount docno  \n",
       "0     1          623.0            86.0                     136.0  5295  \n",
       "1     2           85.0            60.0                       3.0  7753  \n",
       "2     3           59.0            13.0                       6.0  3979  \n",
       "3     4           70.0            49.0                       8.0  5646  \n",
       "4     5           70.0            53.0                       3.0  3809  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_info_df.to_pickle('data/extra_info.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For similarity model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_info_df = data_df[['title', 'area', 'title_embeddings', 'abstract_embeddings', 'total_embeddings']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_info_df = papers_info_df.groupby(['title']).agg({'title': 'first', 'title_embeddings': 'first', 'abstract_embeddings': 'first',  'total_embeddings': 'first', 'area': lambda x: set(*x)}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_info_df = papers_info_df.merge(papers[['docno', 'title']], on='title', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>title_embeddings</th>\n",
       "      <th>abstract_embeddings</th>\n",
       "      <th>total_embeddings</th>\n",
       "      <th>area</th>\n",
       "      <th>docno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"zero-shot\" super-resolution using deep intern...</td>\n",
       "      <td>[-0.07775616, 0.05288399, 0.03650218, 0.038884...</td>\n",
       "      <td>[0.012619468, 0.06828206, -0.0018017464, 0.002...</td>\n",
       "      <td>[-0.022982784, 0.07698608, 0.0030802086, 0.034...</td>\n",
       "      <td>{Image Compression, Super-Resolution}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(blockchain technology and industry 4.0 at aut...</td>\n",
       "      <td>[-0.020874746, 0.028415756, -0.016895752, 0.05...</td>\n",
       "      <td>[0.012619468, 0.06828206, -0.0018017464, 0.002...</td>\n",
       "      <td>[-0.021961384, 0.0038702078, -0.02499763, 0.01...</td>\n",
       "      <td>{Autonomous vehicles}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(male, bachelor) and (female, ph.d) have diffe...</td>\n",
       "      <td>[0.05497964, 0.056969024, -0.04139412, 0.01792...</td>\n",
       "      <td>[0.012619468, 0.06828206, -0.0018017464, 0.002...</td>\n",
       "      <td>[0.038503695, 0.093446776, -0.04756615, 0.0151...</td>\n",
       "      <td>{Style Transfer}</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>124-color super-resolution imaging by engineer...</td>\n",
       "      <td>[0.0032263368, 0.015332368, -0.0021535154, -0....</td>\n",
       "      <td>[0.012619468, 0.06828206, -0.0018017464, 0.002...</td>\n",
       "      <td>[-0.0019260754, -0.0055030133, 0.005773849, -0...</td>\n",
       "      <td>{Super-Resolution}</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1st place solution for ava-kinetics crossover ...</td>\n",
       "      <td>[-0.06893435, -0.011644914, -0.035723064, 0.04...</td>\n",
       "      <td>[0.012619468, 0.06828206, -0.0018017464, 0.002...</td>\n",
       "      <td>[-0.05613881, -0.00845654, -0.020145206, 0.050...</td>\n",
       "      <td>{Action Recognition}</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  \"zero-shot\" super-resolution using deep intern...   \n",
       "1  (blockchain technology and industry 4.0 at aut...   \n",
       "2  (male, bachelor) and (female, ph.d) have diffe...   \n",
       "3  124-color super-resolution imaging by engineer...   \n",
       "4  1st place solution for ava-kinetics crossover ...   \n",
       "\n",
       "                                    title_embeddings  \\\n",
       "0  [-0.07775616, 0.05288399, 0.03650218, 0.038884...   \n",
       "1  [-0.020874746, 0.028415756, -0.016895752, 0.05...   \n",
       "2  [0.05497964, 0.056969024, -0.04139412, 0.01792...   \n",
       "3  [0.0032263368, 0.015332368, -0.0021535154, -0....   \n",
       "4  [-0.06893435, -0.011644914, -0.035723064, 0.04...   \n",
       "\n",
       "                                 abstract_embeddings  \\\n",
       "0  [0.012619468, 0.06828206, -0.0018017464, 0.002...   \n",
       "1  [0.012619468, 0.06828206, -0.0018017464, 0.002...   \n",
       "2  [0.012619468, 0.06828206, -0.0018017464, 0.002...   \n",
       "3  [0.012619468, 0.06828206, -0.0018017464, 0.002...   \n",
       "4  [0.012619468, 0.06828206, -0.0018017464, 0.002...   \n",
       "\n",
       "                                    total_embeddings  \\\n",
       "0  [-0.022982784, 0.07698608, 0.0030802086, 0.034...   \n",
       "1  [-0.021961384, 0.0038702078, -0.02499763, 0.01...   \n",
       "2  [0.038503695, 0.093446776, -0.04756615, 0.0151...   \n",
       "3  [-0.0019260754, -0.0055030133, 0.005773849, -0...   \n",
       "4  [-0.05613881, -0.00845654, -0.020145206, 0.050...   \n",
       "\n",
       "                                    area docno  \n",
       "0  {Image Compression, Super-Resolution}     0  \n",
       "1                  {Autonomous vehicles}     1  \n",
       "2                       {Style Transfer}     2  \n",
       "3                     {Super-Resolution}     3  \n",
       "4                   {Action Recognition}     4  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_info_df.to_pickle('data/papers_info.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>title</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I would like to reconstruct 3D models from ima...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>infinitam v3: a framework for large-scale 3d r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Volumetric models have become a popular repres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I would like to reconstruct 3D models from ima...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>image2mesh: a learning framework for single im...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>One challenge that remains open in 3D deep lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I would like to reconstruct 3D models from ima...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>video based reconstruction of 3d people models</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This paper describes a method to obtain accura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I would like to reconstruct 3D models from ima...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>differentiable volumetric rendering: learning ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Learning-based 3D reconstruction methods have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I would like to reconstruct 3D models from ima...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>implicit functions in feature space for 3d sha...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>While many works focus on 3D reconstruction fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>I would like to imprve the resolution of an im...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>towards a mathematical theory of superâ€resol...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>After motivating the need of a multiscale vers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>I would like to imprve the resolution of an im...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>super-resolution image reconstruction: a techn...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Face super-resolution (FSR), also known as fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>I would like to imprve the resolution of an im...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>space-time super-resolution</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The concept of the space-time as emerging in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>I would like to imprve the resolution of an im...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>super-resolution in medical imaging</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Although high resolution isotropic 3D medical ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>I would like to imprve the resolution of an im...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>computer vision applied to super resolution</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The first mobile camera phone was sold only 20...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  query  Unnamed: 1  \\\n",
       "0     I would like to reconstruct 3D models from ima...         NaN   \n",
       "1     I would like to reconstruct 3D models from ima...         NaN   \n",
       "2     I would like to reconstruct 3D models from ima...         NaN   \n",
       "3     I would like to reconstruct 3D models from ima...         NaN   \n",
       "4     I would like to reconstruct 3D models from ima...         NaN   \n",
       "...                                                 ...         ...   \n",
       "2995  I would like to imprve the resolution of an im...         NaN   \n",
       "2996  I would like to imprve the resolution of an im...         NaN   \n",
       "2997  I would like to imprve the resolution of an im...         NaN   \n",
       "2998  I would like to imprve the resolution of an im...         NaN   \n",
       "2999  I would like to imprve the resolution of an im...         NaN   \n",
       "\n",
       "      Unnamed: 2                                              title  \\\n",
       "0            NaN  infinitam v3: a framework for large-scale 3d r...   \n",
       "1            NaN  image2mesh: a learning framework for single im...   \n",
       "2            NaN     video based reconstruction of 3d people models   \n",
       "3            NaN  differentiable volumetric rendering: learning ...   \n",
       "4            NaN  implicit functions in feature space for 3d sha...   \n",
       "...          ...                                                ...   \n",
       "2995         NaN  towards a mathematical theory of superâ€resol...   \n",
       "2996         NaN  super-resolution image reconstruction: a techn...   \n",
       "2997         NaN                        space-time super-resolution   \n",
       "2998         NaN                super-resolution in medical imaging   \n",
       "2999         NaN        computer vision applied to super resolution   \n",
       "\n",
       "      Unnamed: 4  Unnamed: 5  Unnamed: 6  Unnamed: 7  Unnamed: 8  Unnamed: 9  \\\n",
       "0            NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "1            NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "2            NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "3            NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "4            NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2995         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "2996         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "2997         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "2998         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "2999         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "      Unnamed: 10  Unnamed: 11  Unnamed: 12  \\\n",
       "0             NaN          NaN          NaN   \n",
       "1             NaN          NaN          NaN   \n",
       "2             NaN          NaN          NaN   \n",
       "3             NaN          NaN          NaN   \n",
       "4             NaN          NaN          NaN   \n",
       "...           ...          ...          ...   \n",
       "2995          NaN          NaN          NaN   \n",
       "2996          NaN          NaN          NaN   \n",
       "2997          NaN          NaN          NaN   \n",
       "2998          NaN          NaN          NaN   \n",
       "2999          NaN          NaN          NaN   \n",
       "\n",
       "                                               abstract  \n",
       "0     Volumetric models have become a popular repres...  \n",
       "1     One challenge that remains open in 3D deep lea...  \n",
       "2     This paper describes a method to obtain accura...  \n",
       "3     Learning-based 3D reconstruction methods have ...  \n",
       "4     While many works focus on 3D reconstruction fr...  \n",
       "...                                                 ...  \n",
       "2995  After motivating the need of a multiscale vers...  \n",
       "2996  Face super-resolution (FSR), also known as fac...  \n",
       "2997  The concept of the space-time as emerging in t...  \n",
       "2998  Although high resolution isotropic 3D medical ...  \n",
       "2999  The first mobile camera phone was sold only 20...  \n",
       "\n",
       "[3000 rows x 14 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[['title', 'query']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>title_embeddings</th>\n",
       "      <th>abstract_embeddings</th>\n",
       "      <th>total_embeddings</th>\n",
       "      <th>area</th>\n",
       "      <th>docno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"zero-shot\" super-resolution using deep intern...</td>\n",
       "      <td>[-0.07775616, 0.05288399, 0.03650218, 0.038884...</td>\n",
       "      <td>[0.012619468, 0.06828206, -0.0018017464, 0.002...</td>\n",
       "      <td>[-0.022982784, 0.07698608, 0.0030802086, 0.034...</td>\n",
       "      <td>{Image Compression, Super-Resolution}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(blockchain technology and industry 4.0 at aut...</td>\n",
       "      <td>[-0.020874746, 0.028415756, -0.016895752, 0.05...</td>\n",
       "      <td>[0.012619468, 0.06828206, -0.0018017464, 0.002...</td>\n",
       "      <td>[-0.021961384, 0.0038702078, -0.02499763, 0.01...</td>\n",
       "      <td>{Autonomous vehicles}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(male, bachelor) and (female, ph.d) have diffe...</td>\n",
       "      <td>[0.05497964, 0.056969024, -0.04139412, 0.01792...</td>\n",
       "      <td>[0.012619468, 0.06828206, -0.0018017464, 0.002...</td>\n",
       "      <td>[0.038503695, 0.093446776, -0.04756615, 0.0151...</td>\n",
       "      <td>{Style Transfer}</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>124-color super-resolution imaging by engineer...</td>\n",
       "      <td>[0.0032263368, 0.015332368, -0.0021535154, -0....</td>\n",
       "      <td>[0.012619468, 0.06828206, -0.0018017464, 0.002...</td>\n",
       "      <td>[-0.0019260754, -0.0055030133, 0.005773849, -0...</td>\n",
       "      <td>{Super-Resolution}</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1st place solution for ava-kinetics crossover ...</td>\n",
       "      <td>[-0.06893435, -0.011644914, -0.035723064, 0.04...</td>\n",
       "      <td>[0.012619468, 0.06828206, -0.0018017464, 0.002...</td>\n",
       "      <td>[-0.05613881, -0.00845654, -0.020145206, 0.050...</td>\n",
       "      <td>{Action Recognition}</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7860</th>\n",
       "      <td>zooming slowmo: an efficient one-stage framewo...</td>\n",
       "      <td>[-0.030745365, 0.016652511, 0.02880512, 0.0043...</td>\n",
       "      <td>[0.012619468, 0.06828206, -0.0018017464, 0.002...</td>\n",
       "      <td>[-0.028682087, 0.05198012, 0.033375114, 0.0397...</td>\n",
       "      <td>{Super-Resolution}</td>\n",
       "      <td>7860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7861</th>\n",
       "      <td>α7nachr/nmdar coupling affects nmdar function ...</td>\n",
       "      <td>[-0.013007551, 0.03416746, 0.004286104, 0.0203...</td>\n",
       "      <td>[0.012619468, 0.06828206, -0.0018017464, 0.002...</td>\n",
       "      <td>[-0.017490184, 0.08755458, -0.020279747, 0.013...</td>\n",
       "      <td>{Object Recognition}</td>\n",
       "      <td>7861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7862</th>\n",
       "      <td>“i've seen it all before”: explaining age-rela...</td>\n",
       "      <td>[0.009059156, 0.027311925, 0.0058719674, 0.024...</td>\n",
       "      <td>[0.012619468, 0.06828206, -0.0018017464, 0.002...</td>\n",
       "      <td>[0.0071213795, -0.024961853, 0.0179813, 0.0040...</td>\n",
       "      <td>{Object Recognition}</td>\n",
       "      <td>7862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7863</th>\n",
       "      <td>… graft augmentation for severe glenoid bone l...</td>\n",
       "      <td>[0.03842942, 2.0709778e-05, -0.021613646, 0.02...</td>\n",
       "      <td>[0.012619468, 0.06828206, -0.0018017464, 0.002...</td>\n",
       "      <td>[0.013518965, -0.022561295, -0.035119504, 0.01...</td>\n",
       "      <td>{Image augmentation}</td>\n",
       "      <td>7863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7864</th>\n",
       "      <td>… studies of n, n-bis -1, 8-naphthalenediamine...</td>\n",
       "      <td>[-0.013535921, -0.018312858, -0.002104915, -0....</td>\n",
       "      <td>[0.012619468, 0.06828206, -0.0018017464, 0.002...</td>\n",
       "      <td>[-0.029758533, -0.016643245, 0.012274956, -0.0...</td>\n",
       "      <td>{Image generation}</td>\n",
       "      <td>7864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7865 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0     \"zero-shot\" super-resolution using deep intern...   \n",
       "1     (blockchain technology and industry 4.0 at aut...   \n",
       "2     (male, bachelor) and (female, ph.d) have diffe...   \n",
       "3     124-color super-resolution imaging by engineer...   \n",
       "4     1st place solution for ava-kinetics crossover ...   \n",
       "...                                                 ...   \n",
       "7860  zooming slowmo: an efficient one-stage framewo...   \n",
       "7861  α7nachr/nmdar coupling affects nmdar function ...   \n",
       "7862  “i've seen it all before”: explaining age-rela...   \n",
       "7863  … graft augmentation for severe glenoid bone l...   \n",
       "7864  … studies of n, n-bis -1, 8-naphthalenediamine...   \n",
       "\n",
       "                                       title_embeddings  \\\n",
       "0     [-0.07775616, 0.05288399, 0.03650218, 0.038884...   \n",
       "1     [-0.020874746, 0.028415756, -0.016895752, 0.05...   \n",
       "2     [0.05497964, 0.056969024, -0.04139412, 0.01792...   \n",
       "3     [0.0032263368, 0.015332368, -0.0021535154, -0....   \n",
       "4     [-0.06893435, -0.011644914, -0.035723064, 0.04...   \n",
       "...                                                 ...   \n",
       "7860  [-0.030745365, 0.016652511, 0.02880512, 0.0043...   \n",
       "7861  [-0.013007551, 0.03416746, 0.004286104, 0.0203...   \n",
       "7862  [0.009059156, 0.027311925, 0.0058719674, 0.024...   \n",
       "7863  [0.03842942, 2.0709778e-05, -0.021613646, 0.02...   \n",
       "7864  [-0.013535921, -0.018312858, -0.002104915, -0....   \n",
       "\n",
       "                                    abstract_embeddings  \\\n",
       "0     [0.012619468, 0.06828206, -0.0018017464, 0.002...   \n",
       "1     [0.012619468, 0.06828206, -0.0018017464, 0.002...   \n",
       "2     [0.012619468, 0.06828206, -0.0018017464, 0.002...   \n",
       "3     [0.012619468, 0.06828206, -0.0018017464, 0.002...   \n",
       "4     [0.012619468, 0.06828206, -0.0018017464, 0.002...   \n",
       "...                                                 ...   \n",
       "7860  [0.012619468, 0.06828206, -0.0018017464, 0.002...   \n",
       "7861  [0.012619468, 0.06828206, -0.0018017464, 0.002...   \n",
       "7862  [0.012619468, 0.06828206, -0.0018017464, 0.002...   \n",
       "7863  [0.012619468, 0.06828206, -0.0018017464, 0.002...   \n",
       "7864  [0.012619468, 0.06828206, -0.0018017464, 0.002...   \n",
       "\n",
       "                                       total_embeddings  \\\n",
       "0     [-0.022982784, 0.07698608, 0.0030802086, 0.034...   \n",
       "1     [-0.021961384, 0.0038702078, -0.02499763, 0.01...   \n",
       "2     [0.038503695, 0.093446776, -0.04756615, 0.0151...   \n",
       "3     [-0.0019260754, -0.0055030133, 0.005773849, -0...   \n",
       "4     [-0.05613881, -0.00845654, -0.020145206, 0.050...   \n",
       "...                                                 ...   \n",
       "7860  [-0.028682087, 0.05198012, 0.033375114, 0.0397...   \n",
       "7861  [-0.017490184, 0.08755458, -0.020279747, 0.013...   \n",
       "7862  [0.0071213795, -0.024961853, 0.0179813, 0.0040...   \n",
       "7863  [0.013518965, -0.022561295, -0.035119504, 0.01...   \n",
       "7864  [-0.029758533, -0.016643245, 0.012274956, -0.0...   \n",
       "\n",
       "                                       area docno  \n",
       "0     {Image Compression, Super-Resolution}     0  \n",
       "1                     {Autonomous vehicles}     1  \n",
       "2                          {Style Transfer}     2  \n",
       "3                        {Super-Resolution}     3  \n",
       "4                      {Action Recognition}     4  \n",
       "...                                     ...   ...  \n",
       "7860                     {Super-Resolution}  7860  \n",
       "7861                   {Object Recognition}  7861  \n",
       "7862                   {Object Recognition}  7862  \n",
       "7863                   {Image augmentation}  7863  \n",
       "7864                     {Image generation}  7864  \n",
       "\n",
       "[7865 rows x 6 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.merge(papers[['title', 'docno']], on='title', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_df.merge(data_df[['title', 'area']], on='title', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.dropna()\n",
    "test.drop_duplicates(subset=['query', 'title'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.groupby('query').head(20).to_csv('./data/test_set_20.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = test[['query', 'area', 'docno']].groupby(['query', 'area']).count().sort_values(by='docno', ascending=False).head(30).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = queries[['query', 'area']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries['qid'] = queries.index.to_series().apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.merge(queries[['qid', 'query']], on='query', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries.to_csv('data/queries.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('data/test_set.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>query</th>\n",
       "      <th>docno</th>\n",
       "      <th>area</th>\n",
       "      <th>qid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>infinitam v3: a framework for large-scale 3d r...</td>\n",
       "      <td>I would like to reconstruct 3D models from ima...</td>\n",
       "      <td>3979</td>\n",
       "      <td>3D Reconstruction</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image2mesh: a learning framework for single im...</td>\n",
       "      <td>I would like to reconstruct 3D models from ima...</td>\n",
       "      <td>3809</td>\n",
       "      <td>3D Reconstruction</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>video based reconstruction of 3d people models</td>\n",
       "      <td>I would like to reconstruct 3D models from ima...</td>\n",
       "      <td>7620</td>\n",
       "      <td>3D Reconstruction</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>differentiable volumetric rendering: learning ...</td>\n",
       "      <td>I would like to reconstruct 3D models from ima...</td>\n",
       "      <td>2269</td>\n",
       "      <td>3D Reconstruction</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>implicit functions in feature space for 3d sha...</td>\n",
       "      <td>I would like to reconstruct 3D models from ima...</td>\n",
       "      <td>3823</td>\n",
       "      <td>3D Reconstruction</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2968</th>\n",
       "      <td>example-based super-resolution</td>\n",
       "      <td>I would like to imprve the resolution of an im...</td>\n",
       "      <td>2708</td>\n",
       "      <td>Super-Resolution</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2969</th>\n",
       "      <td>super-resolution image reconstruction: a techn...</td>\n",
       "      <td>I would like to imprve the resolution of an im...</td>\n",
       "      <td>6906</td>\n",
       "      <td>Super-Resolution</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2970</th>\n",
       "      <td>space-time super-resolution</td>\n",
       "      <td>I would like to imprve the resolution of an im...</td>\n",
       "      <td>6685</td>\n",
       "      <td>Super-Resolution</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2971</th>\n",
       "      <td>super-resolution in medical imaging</td>\n",
       "      <td>I would like to imprve the resolution of an im...</td>\n",
       "      <td>6909</td>\n",
       "      <td>Super-Resolution</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2972</th>\n",
       "      <td>computer vision applied to super resolution</td>\n",
       "      <td>I would like to imprve the resolution of an im...</td>\n",
       "      <td>1561</td>\n",
       "      <td>Super-Resolution</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2973 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0     infinitam v3: a framework for large-scale 3d r...   \n",
       "1     image2mesh: a learning framework for single im...   \n",
       "2        video based reconstruction of 3d people models   \n",
       "3     differentiable volumetric rendering: learning ...   \n",
       "4     implicit functions in feature space for 3d sha...   \n",
       "...                                                 ...   \n",
       "2968                     example-based super-resolution   \n",
       "2969  super-resolution image reconstruction: a techn...   \n",
       "2970                        space-time super-resolution   \n",
       "2971                super-resolution in medical imaging   \n",
       "2972        computer vision applied to super resolution   \n",
       "\n",
       "                                                  query docno  \\\n",
       "0     I would like to reconstruct 3D models from ima...  3979   \n",
       "1     I would like to reconstruct 3D models from ima...  3809   \n",
       "2     I would like to reconstruct 3D models from ima...  7620   \n",
       "3     I would like to reconstruct 3D models from ima...  2269   \n",
       "4     I would like to reconstruct 3D models from ima...  3823   \n",
       "...                                                 ...   ...   \n",
       "2968  I would like to imprve the resolution of an im...  2708   \n",
       "2969  I would like to imprve the resolution of an im...  6906   \n",
       "2970  I would like to imprve the resolution of an im...  6685   \n",
       "2971  I would like to imprve the resolution of an im...  6909   \n",
       "2972  I would like to imprve the resolution of an im...  1561   \n",
       "\n",
       "                   area qid  \n",
       "0     3D Reconstruction  13  \n",
       "1     3D Reconstruction  13  \n",
       "2     3D Reconstruction  13  \n",
       "3     3D Reconstruction  13  \n",
       "4     3D Reconstruction  13  \n",
       "...                 ...  ..  \n",
       "2968   Super-Resolution  23  \n",
       "2969   Super-Resolution  23  \n",
       "2970   Super-Resolution  23  \n",
       "2971   Super-Resolution  23  \n",
       "2972   Super-Resolution  23  \n",
       "\n",
       "[2973 rows x 5 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.merge(papers[['title', 'docno']], on='title', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>rank_gs</th>\n",
       "      <th>title</th>\n",
       "      <th>rate_gs</th>\n",
       "      <th>rank_pc</th>\n",
       "      <th>rate_pc</th>\n",
       "      <th>rank_ss</th>\n",
       "      <th>rate_ss</th>\n",
       "      <th>agg_rate</th>\n",
       "      <th>agg_rank</th>\n",
       "      <th>...</th>\n",
       "      <th>pdf_link</th>\n",
       "      <th>abstract</th>\n",
       "      <th>file_name</th>\n",
       "      <th>citationCount</th>\n",
       "      <th>referenceCount</th>\n",
       "      <th>influentialCitationCount</th>\n",
       "      <th>title_embeddings</th>\n",
       "      <th>abstract_embeddings</th>\n",
       "      <th>total_embeddings</th>\n",
       "      <th>docno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D Reconstruction</td>\n",
       "      <td>9.0</td>\n",
       "      <td>occupancy networks: learning 3d reconstruction...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>...</td>\n",
       "      <td>http://openaccess.thecvf.com/content_CVPR_2019...</td>\n",
       "      <td>With the advent of deep neural networks, learn...</td>\n",
       "      <td>3ocnele3dreinfusp</td>\n",
       "      <td>623.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>[-0.05088244, 0.053124595, 0.0023723403, 0.022...</td>\n",
       "      <td>[0.012619468, 0.06828206, -0.0018017464, 0.002...</td>\n",
       "      <td>[-0.060328517, 0.06280401, 0.026933515, 0.0345...</td>\n",
       "      <td>5295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3D Reconstruction</td>\n",
       "      <td>68.0</td>\n",
       "      <td>weakly supervised 3d reconstruction with adver...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>30.7</td>\n",
       "      <td>...</td>\n",
       "      <td>https://arxiv.org/pdf/1705.10904</td>\n",
       "      <td>Supervised 3D reconstruction has witnessed a s...</td>\n",
       "      <td>3wesu3drewiadco</td>\n",
       "      <td>85.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[0.041443087, 0.09971384, 0.034612227, 0.05238...</td>\n",
       "      <td>[0.012619468, 0.06828206, -0.0018017464, 0.002...</td>\n",
       "      <td>[-0.014805883, 0.093130484, 0.03753042, 0.0462...</td>\n",
       "      <td>7753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3D Reconstruction</td>\n",
       "      <td>95.0</td>\n",
       "      <td>infinitam v3: a framework for large-scale 3d r...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>44.9</td>\n",
       "      <td>...</td>\n",
       "      <td>https://arxiv.org/pdf/1708.00783</td>\n",
       "      <td>Volumetric models have become a popular repres...</td>\n",
       "      <td>3inv3afrfola3drewilocl</td>\n",
       "      <td>59.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[-0.027944634, 0.058888804, 0.016118925, 0.007...</td>\n",
       "      <td>[0.012619468, 0.06828206, -0.0018017464, 0.002...</td>\n",
       "      <td>[0.007331516, -0.0009151098, 0.054103583, 0.03...</td>\n",
       "      <td>3979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3D Reconstruction</td>\n",
       "      <td>30.0</td>\n",
       "      <td>pix2vox: context-aware 3d reconstruction from ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>28.5</td>\n",
       "      <td>...</td>\n",
       "      <td>http://openaccess.thecvf.com/content_ICCV_2019...</td>\n",
       "      <td>Recovering the 3D representation of an object ...</td>\n",
       "      <td>3pico3drefrsianmuim</td>\n",
       "      <td>70.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[-0.03636022, 0.038363226, 0.06699201, 0.05293...</td>\n",
       "      <td>[0.012619468, 0.06828206, -0.0018017464, 0.002...</td>\n",
       "      <td>[-0.021163054, 0.089947246, 0.057269774, 0.069...</td>\n",
       "      <td>5646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3D Reconstruction</td>\n",
       "      <td>33.0</td>\n",
       "      <td>image2mesh: a learning framework for single im...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>52.0</td>\n",
       "      <td>...</td>\n",
       "      <td>https://arxiv.org/pdf/1711.10669</td>\n",
       "      <td>One challenge that remains open in 3D deep lea...</td>\n",
       "      <td>3imalefrfosiim3dre</td>\n",
       "      <td>70.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[-0.046021443, 0.087248586, 0.038778853, 0.037...</td>\n",
       "      <td>[0.012619468, 0.06828206, -0.0018017464, 0.002...</td>\n",
       "      <td>[-0.08701608, 0.06889409, 0.028026856, 0.01509...</td>\n",
       "      <td>3809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8250</th>\n",
       "      <td>Super-Resolution</td>\n",
       "      <td>401.0</td>\n",
       "      <td>hyperspectral image super-resolution using dee...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>258.6</td>\n",
       "      <td>...</td>\n",
       "      <td>http://arxiv.org/pdf/1905.09211v1</td>\n",
       "      <td>Abstract Limited by the existed imagery hardwa...</td>\n",
       "      <td>Shyimsuusdeconene</td>\n",
       "      <td>69.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[-0.01713901, 0.027642196, 0.012370186, 0.0398...</td>\n",
       "      <td>[0.012619468, 0.06828206, -0.0018017464, 0.002...</td>\n",
       "      <td>[0.012876433, 0.04741985, 0.0039633377, -0.001...</td>\n",
       "      <td>3608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8251</th>\n",
       "      <td>Super-Resolution</td>\n",
       "      <td>401.0</td>\n",
       "      <td>quantitative super-resolution imaging with qpa...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>259.2</td>\n",
       "      <td>...</td>\n",
       "      <td>http://arxiv.org/abs/2011.15052v1</td>\n",
       "      <td>Counting molecules in complexes is challenging...</td>\n",
       "      <td>Squsuimwiqpustrbian</td>\n",
       "      <td>173.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.04307452, -0.010083245, -0.025073582, 0.00...</td>\n",
       "      <td>[0.012619468, 0.06828206, -0.0018017464, 0.002...</td>\n",
       "      <td>[-0.02646856, 0.003393217, -0.017404953, -0.00...</td>\n",
       "      <td>5833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8252</th>\n",
       "      <td>Super-Resolution</td>\n",
       "      <td>401.0</td>\n",
       "      <td>robust single image super-resolution via deep ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>259.8</td>\n",
       "      <td>...</td>\n",
       "      <td>http://arxiv.org/pdf/2006.08857v1</td>\n",
       "      <td>Single image super-resolution (SR) is an ill-p...</td>\n",
       "      <td>Srosiimsuvidenewisppr</td>\n",
       "      <td>112.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[-0.027699452, 0.06728266, 0.03679345, 0.02347...</td>\n",
       "      <td>[0.012619468, 0.06828206, -0.0018017464, 0.002...</td>\n",
       "      <td>[-0.0063791964, 0.095465, 0.034922574, 0.00885...</td>\n",
       "      <td>6238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8253</th>\n",
       "      <td>Super-Resolution</td>\n",
       "      <td>401.0</td>\n",
       "      <td>support recovery for sparse super-resolution o...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>260.4</td>\n",
       "      <td>...</td>\n",
       "      <td>http://arxiv.org/pdf/1003.0888v1</td>\n",
       "      <td>We study sparse spikes super-resolution over t...</td>\n",
       "      <td>Ssurefospsuofpome</td>\n",
       "      <td>62.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[-0.094009355, 0.013627753, 0.017686302, -0.00...</td>\n",
       "      <td>[0.012619468, 0.06828206, -0.0018017464, 0.002...</td>\n",
       "      <td>[-0.034272734, 0.008217079, 0.0050220564, 0.05...</td>\n",
       "      <td>6936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8254</th>\n",
       "      <td>Super-Resolution</td>\n",
       "      <td>401.0</td>\n",
       "      <td>balanced two-stage residual networks for image...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>260.7</td>\n",
       "      <td>...</td>\n",
       "      <td>http://arxiv.org/pdf/1909.12117v2</td>\n",
       "      <td>In this paper, balanced two-stage residual net...</td>\n",
       "      <td>Sbatwrenefoimsu</td>\n",
       "      <td>63.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.0034476737, 0.03991083, 0.0023420046, 0.058...</td>\n",
       "      <td>[0.012619468, 0.06828206, -0.0018017464, 0.002...</td>\n",
       "      <td>[0.007633338, 0.03903806, 0.0110980645, 0.0752...</td>\n",
       "      <td>1178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8255 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   area  rank_gs  \\\n",
       "0     3D Reconstruction      9.0   \n",
       "1     3D Reconstruction     68.0   \n",
       "2     3D Reconstruction     95.0   \n",
       "3     3D Reconstruction     30.0   \n",
       "4     3D Reconstruction     33.0   \n",
       "...                 ...      ...   \n",
       "8250   Super-Resolution    401.0   \n",
       "8251   Super-Resolution    401.0   \n",
       "8252   Super-Resolution    401.0   \n",
       "8253   Super-Resolution    401.0   \n",
       "8254   Super-Resolution    401.0   \n",
       "\n",
       "                                                  title  rate_gs  rank_pc  \\\n",
       "0     occupancy networks: learning 3d reconstruction...      5.0     18.0   \n",
       "1     weakly supervised 3d reconstruction with adver...      4.0      4.0   \n",
       "2     infinitam v3: a framework for large-scale 3d r...      4.0     17.0   \n",
       "3     pix2vox: context-aware 3d reconstruction from ...      5.0     45.0   \n",
       "4     image2mesh: a learning framework for single im...      5.0     94.0   \n",
       "...                                                 ...      ...      ...   \n",
       "8250  hyperspectral image super-resolution using dee...      1.0    201.0   \n",
       "8251  quantitative super-resolution imaging with qpa...      1.0    201.0   \n",
       "8252  robust single image super-resolution via deep ...      1.0    201.0   \n",
       "8253  support recovery for sparse super-resolution o...      1.0    201.0   \n",
       "8254  balanced two-stage residual networks for image...      1.0    201.0   \n",
       "\n",
       "      rate_pc  rank_ss  rate_ss  agg_rate  agg_rank  ...  \\\n",
       "0         5.0      1.0      5.0       5.0      10.2  ...   \n",
       "1         5.0     29.0      5.0       4.7      30.7  ...   \n",
       "2         5.0     32.0      5.0       4.7      44.9  ...   \n",
       "3         4.0      5.0      5.0       4.6      28.5  ...   \n",
       "4         4.0     15.0      5.0       4.6      52.0  ...   \n",
       "...       ...      ...      ...       ...       ...  ...   \n",
       "8250      1.0    193.0      3.0       1.6     258.6  ...   \n",
       "8251      1.0    195.0      3.0       1.6     259.2  ...   \n",
       "8252      1.0    197.0      3.0       1.6     259.8  ...   \n",
       "8253      1.0    199.0      3.0       1.6     260.4  ...   \n",
       "8254      1.0    200.0      3.0       1.6     260.7  ...   \n",
       "\n",
       "                                               pdf_link  \\\n",
       "0     http://openaccess.thecvf.com/content_CVPR_2019...   \n",
       "1                      https://arxiv.org/pdf/1705.10904   \n",
       "2                      https://arxiv.org/pdf/1708.00783   \n",
       "3     http://openaccess.thecvf.com/content_ICCV_2019...   \n",
       "4                      https://arxiv.org/pdf/1711.10669   \n",
       "...                                                 ...   \n",
       "8250                  http://arxiv.org/pdf/1905.09211v1   \n",
       "8251                  http://arxiv.org/abs/2011.15052v1   \n",
       "8252                  http://arxiv.org/pdf/2006.08857v1   \n",
       "8253                   http://arxiv.org/pdf/1003.0888v1   \n",
       "8254                  http://arxiv.org/pdf/1909.12117v2   \n",
       "\n",
       "                                               abstract  \\\n",
       "0     With the advent of deep neural networks, learn...   \n",
       "1     Supervised 3D reconstruction has witnessed a s...   \n",
       "2     Volumetric models have become a popular repres...   \n",
       "3     Recovering the 3D representation of an object ...   \n",
       "4     One challenge that remains open in 3D deep lea...   \n",
       "...                                                 ...   \n",
       "8250  Abstract Limited by the existed imagery hardwa...   \n",
       "8251  Counting molecules in complexes is challenging...   \n",
       "8252  Single image super-resolution (SR) is an ill-p...   \n",
       "8253  We study sparse spikes super-resolution over t...   \n",
       "8254  In this paper, balanced two-stage residual net...   \n",
       "\n",
       "                   file_name citationCount  referenceCount  \\\n",
       "0          3ocnele3dreinfusp         623.0            86.0   \n",
       "1            3wesu3drewiadco          85.0            60.0   \n",
       "2     3inv3afrfola3drewilocl          59.0            13.0   \n",
       "3        3pico3drefrsianmuim          70.0            49.0   \n",
       "4         3imalefrfosiim3dre          70.0            53.0   \n",
       "...                      ...           ...             ...   \n",
       "8250       Shyimsuusdeconene          69.0            52.0   \n",
       "8251     Squsuimwiqpustrbian         173.0            40.0   \n",
       "8252   Srosiimsuvidenewisppr         112.0            51.0   \n",
       "8253       Ssurefospsuofpome          62.0            24.0   \n",
       "8254         Sbatwrenefoimsu          63.0            44.0   \n",
       "\n",
       "      influentialCitationCount  \\\n",
       "0                        136.0   \n",
       "1                          3.0   \n",
       "2                          6.0   \n",
       "3                          8.0   \n",
       "4                          3.0   \n",
       "...                        ...   \n",
       "8250                       3.0   \n",
       "8251                       0.0   \n",
       "8252                       9.0   \n",
       "8253                       2.0   \n",
       "8254                       1.0   \n",
       "\n",
       "                                       title_embeddings  \\\n",
       "0     [-0.05088244, 0.053124595, 0.0023723403, 0.022...   \n",
       "1     [0.041443087, 0.09971384, 0.034612227, 0.05238...   \n",
       "2     [-0.027944634, 0.058888804, 0.016118925, 0.007...   \n",
       "3     [-0.03636022, 0.038363226, 0.06699201, 0.05293...   \n",
       "4     [-0.046021443, 0.087248586, 0.038778853, 0.037...   \n",
       "...                                                 ...   \n",
       "8250  [-0.01713901, 0.027642196, 0.012370186, 0.0398...   \n",
       "8251  [-0.04307452, -0.010083245, -0.025073582, 0.00...   \n",
       "8252  [-0.027699452, 0.06728266, 0.03679345, 0.02347...   \n",
       "8253  [-0.094009355, 0.013627753, 0.017686302, -0.00...   \n",
       "8254  [0.0034476737, 0.03991083, 0.0023420046, 0.058...   \n",
       "\n",
       "                                    abstract_embeddings  \\\n",
       "0     [0.012619468, 0.06828206, -0.0018017464, 0.002...   \n",
       "1     [0.012619468, 0.06828206, -0.0018017464, 0.002...   \n",
       "2     [0.012619468, 0.06828206, -0.0018017464, 0.002...   \n",
       "3     [0.012619468, 0.06828206, -0.0018017464, 0.002...   \n",
       "4     [0.012619468, 0.06828206, -0.0018017464, 0.002...   \n",
       "...                                                 ...   \n",
       "8250  [0.012619468, 0.06828206, -0.0018017464, 0.002...   \n",
       "8251  [0.012619468, 0.06828206, -0.0018017464, 0.002...   \n",
       "8252  [0.012619468, 0.06828206, -0.0018017464, 0.002...   \n",
       "8253  [0.012619468, 0.06828206, -0.0018017464, 0.002...   \n",
       "8254  [0.012619468, 0.06828206, -0.0018017464, 0.002...   \n",
       "\n",
       "                                       total_embeddings docno  \n",
       "0     [-0.060328517, 0.06280401, 0.026933515, 0.0345...  5295  \n",
       "1     [-0.014805883, 0.093130484, 0.03753042, 0.0462...  7753  \n",
       "2     [0.007331516, -0.0009151098, 0.054103583, 0.03...  3979  \n",
       "3     [-0.021163054, 0.089947246, 0.057269774, 0.069...  5646  \n",
       "4     [-0.08701608, 0.06889409, 0.028026856, 0.01509...  3809  \n",
       "...                                                 ...   ...  \n",
       "8250  [0.012876433, 0.04741985, 0.0039633377, -0.001...  3608  \n",
       "8251  [-0.02646856, 0.003393217, -0.017404953, -0.00...  5833  \n",
       "8252  [-0.0063791964, 0.095465, 0.034922574, 0.00885...  6238  \n",
       "8253  [-0.034272734, 0.008217079, 0.0050220564, 0.05...  6936  \n",
       "8254  [0.007633338, 0.03903806, 0.0110980645, 0.0752...  1178  \n",
       "\n",
       "[8255 rows x 21 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_df = data_df[['title', 'area', 'agg_rate', 'agg_rank', 'docno']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = pd.read_csv('data/queries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>area</th>\n",
       "      <th>qid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I would like to remove the noise from images.</td>\n",
       "      <td>Denoising</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How to add captions to the images?</td>\n",
       "      <td>Image Captioning</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I want to detect the act of people.</td>\n",
       "      <td>Action Recognition</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the action of  people in the image.</td>\n",
       "      <td>Action Recognition</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Object Tracking with Neural Network</td>\n",
       "      <td>Object Tracking</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I would like to track a moving item in a video</td>\n",
       "      <td>Object Tracking</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How do self-driving vehicles work?</td>\n",
       "      <td>Autonomous vehicles</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Change time and season of an image</td>\n",
       "      <td>Domain adaptation</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Can the computer recognize characters in the i...</td>\n",
       "      <td>Optical Character Recognition</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I would like to find all the faces in the image.</td>\n",
       "      <td>Face Recognition</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Hand-writing recognition</td>\n",
       "      <td>Optical Character Recognition</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Image Depth Estimation</td>\n",
       "      <td>Depth Estimation</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>How to increase the amount of data conveyed by...</td>\n",
       "      <td>Image augmentation</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I would like to reconstruct 3D models from ima...</td>\n",
       "      <td>3D Reconstruction</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I would like to reduce the size of images?</td>\n",
       "      <td>Image Compression</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Which of those images have cars on it?</td>\n",
       "      <td>Image classification</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Image Retrievel</td>\n",
       "      <td>Image Retrieval</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>I would like to find similar images .</td>\n",
       "      <td>Image Retrieval</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Can the computer be an artist like Van Gogh?</td>\n",
       "      <td>Style Transfer</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Optical Flow Estimation with Deep Learning</td>\n",
       "      <td>Optical Flow Estimation</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>How fast is the object in the video?</td>\n",
       "      <td>Optical Flow Estimation</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>I would like to generate new images from dataset.</td>\n",
       "      <td>Image generation</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Object Detection</td>\n",
       "      <td>Object detection</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>I would like to improve the resolution of an i...</td>\n",
       "      <td>Super-Resolution</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>What is the pose of people in the image?</td>\n",
       "      <td>Pose estimation</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Can the computer figure out what is on an image?</td>\n",
       "      <td>Object Recognition</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Object recognition with attention</td>\n",
       "      <td>Object Recognition</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Classify all the stuffs in a single image.</td>\n",
       "      <td>Semantic segmentation</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>I would like to separate the background.</td>\n",
       "      <td>Semantic segmentation</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>I want to mark different part of an image</td>\n",
       "      <td>Semantic segmentation</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                query  \\\n",
       "0       I would like to remove the noise from images.   \n",
       "1                  How to add captions to the images?   \n",
       "2                 I want to detect the act of people.   \n",
       "3         What is the action of  people in the image.   \n",
       "4                 Object Tracking with Neural Network   \n",
       "5      I would like to track a moving item in a video   \n",
       "6                  How do self-driving vehicles work?   \n",
       "7                  Change time and season of an image   \n",
       "8   Can the computer recognize characters in the i...   \n",
       "9    I would like to find all the faces in the image.   \n",
       "10                           Hand-writing recognition   \n",
       "11                             Image Depth Estimation   \n",
       "12  How to increase the amount of data conveyed by...   \n",
       "13  I would like to reconstruct 3D models from ima...   \n",
       "14         I would like to reduce the size of images?   \n",
       "15             Which of those images have cars on it?   \n",
       "16                                    Image Retrievel   \n",
       "17              I would like to find similar images .   \n",
       "18      Can the computer be an artist like Van Gogh?    \n",
       "19         Optical Flow Estimation with Deep Learning   \n",
       "20               How fast is the object in the video?   \n",
       "21  I would like to generate new images from dataset.   \n",
       "22                                   Object Detection   \n",
       "23  I would like to improve the resolution of an i...   \n",
       "24           What is the pose of people in the image?   \n",
       "25   Can the computer figure out what is on an image?   \n",
       "26                  Object recognition with attention   \n",
       "27         Classify all the stuffs in a single image.   \n",
       "28           I would like to separate the background.   \n",
       "29          I want to mark different part of an image   \n",
       "\n",
       "                             area  qid  \n",
       "0                       Denoising    0  \n",
       "1                Image Captioning    1  \n",
       "2              Action Recognition    2  \n",
       "3              Action Recognition    3  \n",
       "4                 Object Tracking    4  \n",
       "5                 Object Tracking    5  \n",
       "6             Autonomous vehicles    6  \n",
       "7               Domain adaptation    7  \n",
       "8   Optical Character Recognition    8  \n",
       "9                Face Recognition    9  \n",
       "10  Optical Character Recognition   10  \n",
       "11               Depth Estimation   11  \n",
       "12             Image augmentation   12  \n",
       "13              3D Reconstruction   13  \n",
       "14              Image Compression   14  \n",
       "15           Image classification   15  \n",
       "16                Image Retrieval   16  \n",
       "17                Image Retrieval   17  \n",
       "18                 Style Transfer   18  \n",
       "19        Optical Flow Estimation   19  \n",
       "20        Optical Flow Estimation   20  \n",
       "21               Image generation   21  \n",
       "22               Object detection   22  \n",
       "23               Super-Resolution   23  \n",
       "24                Pose estimation   24  \n",
       "25             Object Recognition   25  \n",
       "26             Object Recognition   26  \n",
       "27          Semantic segmentation   27  \n",
       "28          Semantic segmentation   28  \n",
       "29          Semantic segmentation   29  "
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>area</th>\n",
       "      <th>agg_rate</th>\n",
       "      <th>agg_rank</th>\n",
       "      <th>docno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>occupancy networks: learning 3d reconstruction...</td>\n",
       "      <td>3D Reconstruction</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weakly supervised 3d reconstruction with adver...</td>\n",
       "      <td>3D Reconstruction</td>\n",
       "      <td>4.7</td>\n",
       "      <td>30.7</td>\n",
       "      <td>7753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>infinitam v3: a framework for large-scale 3d r...</td>\n",
       "      <td>3D Reconstruction</td>\n",
       "      <td>4.7</td>\n",
       "      <td>44.9</td>\n",
       "      <td>3979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pix2vox: context-aware 3d reconstruction from ...</td>\n",
       "      <td>3D Reconstruction</td>\n",
       "      <td>4.6</td>\n",
       "      <td>28.5</td>\n",
       "      <td>5646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image2mesh: a learning framework for single im...</td>\n",
       "      <td>3D Reconstruction</td>\n",
       "      <td>4.6</td>\n",
       "      <td>52.0</td>\n",
       "      <td>3809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8250</th>\n",
       "      <td>hyperspectral image super-resolution using dee...</td>\n",
       "      <td>Super-Resolution</td>\n",
       "      <td>1.6</td>\n",
       "      <td>258.6</td>\n",
       "      <td>3608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8251</th>\n",
       "      <td>quantitative super-resolution imaging with qpa...</td>\n",
       "      <td>Super-Resolution</td>\n",
       "      <td>1.6</td>\n",
       "      <td>259.2</td>\n",
       "      <td>5833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8252</th>\n",
       "      <td>robust single image super-resolution via deep ...</td>\n",
       "      <td>Super-Resolution</td>\n",
       "      <td>1.6</td>\n",
       "      <td>259.8</td>\n",
       "      <td>6238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8253</th>\n",
       "      <td>support recovery for sparse super-resolution o...</td>\n",
       "      <td>Super-Resolution</td>\n",
       "      <td>1.6</td>\n",
       "      <td>260.4</td>\n",
       "      <td>6936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8254</th>\n",
       "      <td>balanced two-stage residual networks for image...</td>\n",
       "      <td>Super-Resolution</td>\n",
       "      <td>1.6</td>\n",
       "      <td>260.7</td>\n",
       "      <td>1178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8255 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title               area  \\\n",
       "0     occupancy networks: learning 3d reconstruction...  3D Reconstruction   \n",
       "1     weakly supervised 3d reconstruction with adver...  3D Reconstruction   \n",
       "2     infinitam v3: a framework for large-scale 3d r...  3D Reconstruction   \n",
       "3     pix2vox: context-aware 3d reconstruction from ...  3D Reconstruction   \n",
       "4     image2mesh: a learning framework for single im...  3D Reconstruction   \n",
       "...                                                 ...                ...   \n",
       "8250  hyperspectral image super-resolution using dee...   Super-Resolution   \n",
       "8251  quantitative super-resolution imaging with qpa...   Super-Resolution   \n",
       "8252  robust single image super-resolution via deep ...   Super-Resolution   \n",
       "8253  support recovery for sparse super-resolution o...   Super-Resolution   \n",
       "8254  balanced two-stage residual networks for image...   Super-Resolution   \n",
       "\n",
       "      agg_rate  agg_rank docno  \n",
       "0          5.0      10.2  5295  \n",
       "1          4.7      30.7  7753  \n",
       "2          4.7      44.9  3979  \n",
       "3          4.6      28.5  5646  \n",
       "4          4.6      52.0  3809  \n",
       "...        ...       ...   ...  \n",
       "8250       1.6     258.6  3608  \n",
       "8251       1.6     259.2  5833  \n",
       "8252       1.6     259.8  6238  \n",
       "8253       1.6     260.4  6936  \n",
       "8254       1.6     260.7  1178  \n",
       "\n",
       "[8255 rows x 5 columns]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_df = rank_df.merge(queries[['qid', 'area']], on='area', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_test = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_test['rank'] = temp_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2491"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_test[(temp_test['docno'] == '122') & (temp_test['qid'] == '27')]['rank'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_test['qid'] = temp_test['qid'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_df = rank_df.merge(temp_test[['qid', 'docno', 'rank']], on=['qid', 'docno'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_df.fillna(3000, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>area</th>\n",
       "      <th>agg_rate</th>\n",
       "      <th>agg_rank</th>\n",
       "      <th>docno</th>\n",
       "      <th>qid</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>unprocessing images for learned raw denoising</td>\n",
       "      <td>Denoising</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>7466</td>\n",
       "      <td>0</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>denoising diffusion probabilistic models</td>\n",
       "      <td>Denoising</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.4</td>\n",
       "      <td>2125</td>\n",
       "      <td>0</td>\n",
       "      <td>395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>beyond a gaussian denoiser: residual learning ...</td>\n",
       "      <td>Denoising</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.6</td>\n",
       "      <td>1222</td>\n",
       "      <td>0</td>\n",
       "      <td>396.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>toward convolutional blind denoising of real p...</td>\n",
       "      <td>Denoising</td>\n",
       "      <td>4.7</td>\n",
       "      <td>29.9</td>\n",
       "      <td>7207</td>\n",
       "      <td>0</td>\n",
       "      <td>397.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>noise2self: blind denoising by self-supervision</td>\n",
       "      <td>Denoising</td>\n",
       "      <td>4.6</td>\n",
       "      <td>35.3</td>\n",
       "      <td>5119</td>\n",
       "      <td>0</td>\n",
       "      <td>398.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10235</th>\n",
       "      <td>global context for convolutional pose machines</td>\n",
       "      <td>Semantic segmentation</td>\n",
       "      <td>1.8</td>\n",
       "      <td>258.2</td>\n",
       "      <td>3304</td>\n",
       "      <td>29</td>\n",
       "      <td>3000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10238</th>\n",
       "      <td>blenderproc</td>\n",
       "      <td>Semantic segmentation</td>\n",
       "      <td>1.8</td>\n",
       "      <td>259.0</td>\n",
       "      <td>1260</td>\n",
       "      <td>29</td>\n",
       "      <td>3000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10241</th>\n",
       "      <td>pyramid vision transformer: a versatile backbo...</td>\n",
       "      <td>Semantic segmentation</td>\n",
       "      <td>1.8</td>\n",
       "      <td>259.4</td>\n",
       "      <td>5822</td>\n",
       "      <td>29</td>\n",
       "      <td>3000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10529</th>\n",
       "      <td>semantic correlation promoted shape-variant co...</td>\n",
       "      <td>Semantic segmentation</td>\n",
       "      <td>1.6</td>\n",
       "      <td>259.8</td>\n",
       "      <td>6416</td>\n",
       "      <td>29</td>\n",
       "      <td>3000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10244</th>\n",
       "      <td>enforcing temporal consistency in deep learnin...</td>\n",
       "      <td>Semantic segmentation</td>\n",
       "      <td>1.8</td>\n",
       "      <td>260.2</td>\n",
       "      <td>2597</td>\n",
       "      <td>29</td>\n",
       "      <td>3000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11230 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "1620       unprocessing images for learned raw denoising   \n",
       "1621            denoising diffusion probabilistic models   \n",
       "1622   beyond a gaussian denoiser: residual learning ...   \n",
       "1623   toward convolutional blind denoising of real p...   \n",
       "1624     noise2self: blind denoising by self-supervision   \n",
       "...                                                  ...   \n",
       "10235     global context for convolutional pose machines   \n",
       "10238                                        blenderproc   \n",
       "10241  pyramid vision transformer: a versatile backbo...   \n",
       "10529  semantic correlation promoted shape-variant co...   \n",
       "10244  enforcing temporal consistency in deep learnin...   \n",
       "\n",
       "                        area  agg_rate  agg_rank docno  qid    rank  \n",
       "1620               Denoising       5.0      13.4  7466    0   394.0  \n",
       "1621               Denoising       5.0      15.4  2125    0   395.0  \n",
       "1622               Denoising       5.0      20.6  1222    0   396.0  \n",
       "1623               Denoising       4.7      29.9  7207    0   397.0  \n",
       "1624               Denoising       4.6      35.3  5119    0   398.0  \n",
       "...                      ...       ...       ...   ...  ...     ...  \n",
       "10235  Semantic segmentation       1.8     258.2  3304   29  3000.0  \n",
       "10238  Semantic segmentation       1.8     259.0  1260   29  3000.0  \n",
       "10241  Semantic segmentation       1.8     259.4  5822   29  3000.0  \n",
       "10529  Semantic segmentation       1.6     259.8  6416   29  3000.0  \n",
       "10244  Semantic segmentation       1.8     260.2  2597   29  3000.0  \n",
       "\n",
       "[11230 rows x 7 columns]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_df.sort_values(by=['qid', 'rank', 'agg_rank', 'agg_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_df = rank_df[['qid', 'docno', 'title']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_df.to_csv('data/final_test_set.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8a7ad60629c7992fdadfcbec1ee9d18d5ed6e222b8ad46df459875a57fae42b2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
