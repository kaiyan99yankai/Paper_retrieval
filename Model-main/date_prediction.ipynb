{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, centroids, papers, sim='structural'):\n",
    "        if sim == 'structural':\n",
    "            w1 = 0.2\n",
    "            w2 = 1 - w1\n",
    "            self.centroids = {area: centroid[0] * w1 + centroid[1] * w2 for area, centroid in centroids.items()}\n",
    "            papers['embeddings'] = w1 * papers['title_embeddings'] + w2 * papers['abstract_embeddings']\n",
    "            self.papers = papers[['docno', 'title', 'embeddings', 'area']].copy()\n",
    "        elif sim == 'total':\n",
    "            self.centroids = {area: centroid[2] for area, centroid in centroids.items()}\n",
    "            self.papers = papers[['docno', 'title', 'total_embeddings', 'area']].copy()\n",
    "            self.papers.rename(columns={'total_embeddings': 'embeddings'}, inplace=True)\n",
    "        del papers\n",
    "            \n",
    "        # embedding model\n",
    "        self.embedding_model = SentenceTransformer('all-mpnet-base-v2')\n",
    "        \n",
    "        \n",
    "    def predict(self, queries, topk=100):\n",
    "        query_embeddings = self.embedding_model.encode(queries)\n",
    "        results_list = [self.predict_once(query_embeddings[qid], qid, topk) for qid in range(query_embeddings.shape[0])]\n",
    "        return pd.concat(results_list)\n",
    "    \n",
    "    def predict_once(self, query_embedding, qid, topk=100):\n",
    "        top2_areas = sorted(self.centroids.items(), key=lambda x: np.dot(x[1], query_embedding), reverse=True)[:2]\n",
    "        top2_areas = set([area for area, _ in top2_areas])\n",
    "        candidate_papers = self.papers[self.papers['area'].apply(lambda x: bool(x & top2_areas))].copy()   \n",
    "        candidate_papers['score'] = candidate_papers['embeddings'].apply(lambda x: np.dot(x, query_embedding))\n",
    "        result_papers = candidate_papers.sort_values('score', ascending=False).head(topk)\n",
    "        result_papers['qid'] = qid\n",
    "        print('top 2 areas for query {}: {}'.format(qid, top2_areas))\n",
    "        return result_papers[['docno', 'qid', 'title', 'score', 'area']].copy().reset_index(drop=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = pd.read_csv('data/queries.csv')\n",
    "papers = pd.read_pickle('./data/papers_info.pkl')\n",
    "centroids = pickle.load(open('./data/centroids_dict.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(centroids, papers, sim='total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Model(centroids, papers, sim='structural')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 3 areas for query 0: {'Denoising', 'Image Compression'}\n",
      "top 3 areas for query 1: {'Image Captioning', 'Image Retrieval'}\n",
      "top 3 areas for query 2: {'Action Recognition', 'Object Tracking'}\n",
      "top 3 areas for query 3: {'Pose estimation', 'Action Recognition'}\n",
      "top 3 areas for query 4: {'Object Tracking', 'Object detection'}\n",
      "top 3 areas for query 5: {'Object Tracking', 'Optical Flow Estimation'}\n",
      "top 3 areas for query 6: {'Depth Estimation', 'Autonomous vehicles'}\n",
      "top 3 areas for query 7: {'Image Captioning', 'Style Transfer'}\n",
      "top 3 areas for query 8: {'Image Captioning', 'Optical Character Recognition'}\n",
      "top 3 areas for query 9: {'Face Recognition', 'Object detection'}\n",
      "top 3 areas for query 10: {'Image Retrieval', 'Optical Character Recognition'}\n",
      "top 3 areas for query 11: {'Depth Estimation', 'Optical Flow Estimation'}\n",
      "top 3 areas for query 12: {'Image augmentation', 'Image Compression'}\n",
      "top 3 areas for query 13: {'Depth Estimation', '3D Reconstruction'}\n",
      "top 3 areas for query 14: {'Denoising', 'Image Compression'}\n",
      "top 3 areas for query 15: {'Object detection', 'Autonomous vehicles'}\n",
      "top 3 areas for query 16: {'Image Retrieval', 'Image Compression'}\n",
      "top 3 areas for query 17: {'Image Retrieval', 'Image Compression'}\n",
      "top 3 areas for query 18: {'Style Transfer', 'Image augmentation'}\n",
      "top 3 areas for query 19: {'Depth Estimation', 'Optical Flow Estimation'}\n",
      "top 3 areas for query 20: {'Object Tracking', 'Optical Flow Estimation'}\n",
      "top 3 areas for query 21: {'Image augmentation', 'Image generation'}\n",
      "top 3 areas for query 22: {'Object Tracking', 'Object detection'}\n",
      "top 3 areas for query 23: {'Super-Resolution', 'Image Compression'}\n",
      "top 3 areas for query 24: {'Pose estimation', 'Action Recognition'}\n",
      "top 3 areas for query 25: {'Image Retrieval', 'Optical Character Recognition'}\n",
      "top 3 areas for query 26: {'Image Captioning', 'Object detection'}\n",
      "top 3 areas for query 27: {'Image Retrieval', 'Image classification'}\n",
      "top 3 areas for query 28: {'Object detection', 'Semantic segmentation'}\n",
      "top 3 areas for query 29: {'Optical Character Recognition', 'Object detection'}\n"
     ]
    }
   ],
   "source": [
    "results = model.predict(queries['query'].to_list(), topk=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 2 areas for query 0: {'Denoising', 'Image Compression'}\n",
      "top 2 areas for query 1: {'Image Captioning', 'Image Retrieval'}\n",
      "top 2 areas for query 2: {'Action Recognition', 'Object detection'}\n",
      "top 2 areas for query 3: {'Pose estimation', 'Action Recognition'}\n",
      "top 2 areas for query 4: {'Object Tracking', 'Object detection'}\n",
      "top 2 areas for query 5: {'Object Tracking', 'Optical Flow Estimation'}\n",
      "top 2 areas for query 6: {'Object Tracking', 'Autonomous vehicles'}\n",
      "top 2 areas for query 7: {'Image Captioning', 'Style Transfer'}\n",
      "top 2 areas for query 8: {'Optical Character Recognition', 'Image Retrieval'}\n",
      "top 2 areas for query 9: {'Face Recognition', 'Object detection'}\n",
      "top 2 areas for query 10: {'Optical Character Recognition', 'Object Recognition'}\n",
      "top 2 areas for query 11: {'Depth Estimation', 'Optical Flow Estimation'}\n",
      "top 2 areas for query 12: {'Image augmentation', 'Image Compression'}\n",
      "top 2 areas for query 13: {'Depth Estimation', '3D Reconstruction'}\n",
      "top 2 areas for query 14: {'Super-Resolution', 'Image Compression'}\n",
      "top 2 areas for query 15: {'Object detection', 'Autonomous vehicles'}\n",
      "top 2 areas for query 16: {'Object Recognition', 'Image Retrieval'}\n",
      "top 2 areas for query 17: {'Image Captioning', 'Image Retrieval'}\n",
      "top 2 areas for query 18: {'Style Transfer', 'Image generation'}\n",
      "top 2 areas for query 19: {'Semantic segmentation', 'Optical Flow Estimation'}\n",
      "top 2 areas for query 20: {'Object Tracking', 'Optical Flow Estimation'}\n",
      "top 2 areas for query 21: {'Image augmentation', 'Image generation'}\n",
      "top 2 areas for query 22: {'Object Recognition', 'Object detection'}\n",
      "top 2 areas for query 23: {'Super-Resolution', 'Image Compression'}\n",
      "top 2 areas for query 24: {'Pose estimation', 'Action Recognition'}\n",
      "top 2 areas for query 25: {'Optical Character Recognition', 'Image Retrieval'}\n",
      "top 2 areas for query 26: {'Object Recognition', 'Object detection'}\n",
      "top 2 areas for query 27: {'Image classification', 'Object Recognition'}\n",
      "top 2 areas for query 28: {'Semantic segmentation', 'Object detection'}\n",
      "top 2 areas for query 29: {'Object Tracking', 'Object detection'}\n"
     ]
    }
   ],
   "source": [
    "results2 = model2.predict(queries['query'].to_list(), topk=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['docno'] = results['docno'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv('data/final_test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos2score(pos):\n",
    "    if pos < 40:\n",
    "        return 5\n",
    "    elif pos < 100:\n",
    "        return 4\n",
    "    elif pos < 200:\n",
    "        return 3\n",
    "    elif pos < 400:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg(results_docs, test_docs):\n",
    "    results_relative_score = []\n",
    "    for docno in results_docs:\n",
    "        if docno in test_docs:\n",
    "            pos_test = test_docs.index(docno)\n",
    "            relative_score = pos2score(pos_test)\n",
    "            results_relative_score.append(relative_score)\n",
    "        else:\n",
    "            results_relative_score.append(0)\n",
    "    DCG = sum([score/np.log2(pos+2) for pos, score in enumerate(results_relative_score)])\n",
    "    IR_relative_score = sorted(results_relative_score, reverse=True)\n",
    "    IDCG = sum([score/np.log2(pos+2) for pos, score in enumerate(IR_relative_score)])\n",
    "    if IDCG == 0:\n",
    "        return 0\n",
    "    return DCG/IDCG\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qid 13: 0.8790851722477917\n",
      "qid 2: 0.8126123677847049\n",
      "qid 3: 0.8988910674253004\n",
      "qid 6: 0.849701843355969\n",
      "qid 0: 0.8876190225403359\n",
      "qid 11: 0.7944776901452953\n",
      "qid 7: 0.6309297535714575\n",
      "qid 9: 0.7821261439977852\n",
      "qid 1: 0.9175257034998602\n",
      "qid 14: 0.9561446631171914\n",
      "qid 16: 0.9210791956752119\n",
      "qid 17: 0.8123019948353362\n",
      "qid 12: 0.611777657723478\n",
      "qid 15: 0\n",
      "qid 21: 0.828180989275756\n",
      "qid 25: 0\n",
      "qid 26: 0.24465054211822604\n",
      "qid 4: 0.9594397022570066\n",
      "qid 5: 0.8366331157181809\n",
      "qid 22: 0.9198418172225933\n",
      "qid 8: 0.8839190832911996\n",
      "qid 10: 0.8921276357109943\n",
      "qid 19: 0.9303473626864637\n",
      "qid 20: 0.6982628326578658\n",
      "qid 24: 0.9611686061960671\n",
      "qid 27: 0\n",
      "qid 28: 0.42671404644728445\n",
      "qid 29: 0.31546487678572877\n",
      "qid 18: 0.9115267669897291\n",
      "qid 23: 0.81032608223349\n",
      "ndcg: 0.7124291911836769\n"
     ]
    }
   ],
   "source": [
    "qids = test_set['qid'].unique()\n",
    "m1_ndcgs = {qid: 0 for qid in qids}\n",
    "for qid in qids:\n",
    "    qid_test_set = test_set[test_set['qid'] == qid]\n",
    "    qid_result = results[results['qid'] == qid]\n",
    "    q_ndcg = ndcg(qid_result['docno'].to_list(), qid_test_set['docno'].to_list())\n",
    "    m1_ndcgs[qid] = q_ndcg\n",
    "    print('qid {}: {}'.format(qid, q_ndcg))\n",
    "    \n",
    "print('ndcg: {}'.format(sum(m1_ndcgs.values()) / len(m1_ndcgs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2['docno'] = results2['docno'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qid 13: 0.7357585286271314\n",
      "qid 2: 0.5310978742972116\n",
      "qid 3: 0.6883288931777398\n",
      "qid 6: 0.877356031824257\n",
      "qid 0: 0.8353844775734836\n",
      "qid 11: 0.8783848220646756\n",
      "qid 7: 0\n",
      "qid 9: 0.9620195497026582\n",
      "qid 1: 0.8992186952999051\n",
      "qid 14: 0.9472279241043943\n",
      "qid 16: 0.8611278460601425\n",
      "qid 17: 0.8044949356840746\n",
      "qid 12: 0.8269697282424433\n",
      "qid 15: 0\n",
      "qid 21: 0.7910988236039674\n",
      "qid 25: 0\n",
      "qid 26: 0.7800556383147249\n",
      "qid 4: 0.8262577629494149\n",
      "qid 5: 0.8555872638630801\n",
      "qid 22: 0.7537032566793705\n",
      "qid 8: 0.9296209349808456\n",
      "qid 10: 0.8960991819648121\n",
      "qid 19: 0.923157782496923\n",
      "qid 20: 0.5788345373247642\n",
      "qid 24: 0.9187109263942083\n",
      "qid 27: 0\n",
      "qid 28: 0.6075991233176815\n",
      "qid 29: 0.5\n",
      "qid 18: 0.9570003258902541\n",
      "qid 23: 0.8809040992431904\n",
      "ndcg: 0.7015332987893783\n"
     ]
    }
   ],
   "source": [
    "qids = test_set['qid'].unique()\n",
    "m2_ndcgs = {qid: 0 for qid in qids}\n",
    "for qid in qids:\n",
    "    qid_test_set = test_set[test_set['qid'] == qid]\n",
    "    qid_result = results2[results2['qid'] == qid]\n",
    "    q_ndcg = ndcg(qid_result['docno'].to_list(), qid_test_set['docno'].to_list())\n",
    "    m2_ndcgs[qid] = q_ndcg\n",
    "    print('qid {}: {}'.format(qid, q_ndcg))\n",
    "    \n",
    "print('ndcg: {}'.format(sum(m2_ndcgs.values()) / len(m2_ndcgs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate for BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyterrier as pt\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "PyTerrier 0.7.1 has loaded Terrier 5.6 (built by craigmacdonald on 2021-09-17 13:27)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "if not pt.started():\n",
    "    pt.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pt.IndexFactory.of('./data/index/data.properties')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep words in query\n",
    "queries['query'] = queries['query'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/junjayz/miniconda3/lib/python3.9/site-packages/pyterrier/batchretrieve.py:391: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  queries['qid'] = queries['qid'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "br = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
    "bm25_results = br.transform(queries[['qid', 'query']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_results['qid'] = bm25_results['qid'].astype(int)\n",
    "bm25_results['docno'] = bm25_results['docno'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qid 13: 0.8812349356800284\n",
      "qid 2: 0.7119384179147197\n",
      "qid 3: 0.883831510003986\n",
      "qid 6: 0.8279802570655883\n",
      "qid 0: 0.5969374864370421\n",
      "qid 11: 0.9159683719479909\n",
      "qid 7: 0.23981246656813146\n",
      "qid 9: 0.8287984373604472\n",
      "qid 1: 0.8503123308363219\n",
      "qid 14: 0.35216953753213154\n",
      "qid 16: 0\n",
      "qid 17: 0.7703379821030687\n",
      "qid 12: 0.3867064184620594\n",
      "qid 15: 0\n",
      "qid 21: 0.3756778848431553\n",
      "qid 25: 0.37584446348729567\n",
      "qid 26: 0.6810784952669073\n",
      "qid 4: 0.8845576101322127\n",
      "qid 5: 0.8110623428048456\n",
      "qid 22: 0.8172678977133249\n",
      "qid 8: 0.8968718982584183\n",
      "qid 10: 0.8821366180823369\n",
      "qid 19: 0.8775603395686095\n",
      "qid 20: 0.3562071871080222\n",
      "qid 24: 0.9108976569330755\n",
      "qid 27: 0.6798452346149234\n",
      "qid 28: 0.3191081886500419\n",
      "qid 29: 0\n",
      "qid 18: 0.7713011555074298\n",
      "qid 23: 0.5792781240086183\n",
      "ndcg: 0.6154907749630244\n"
     ]
    }
   ],
   "source": [
    "qids = test_set['qid'].unique()\n",
    "bm25_ndcgs = {qid: 0 for qid in qids}\n",
    "for qid in qids:\n",
    "    qid_test_set = test_set[test_set['qid'] == qid]\n",
    "    qid_result = bm25_results[bm25_results['qid'] == qid][:20]\n",
    "    q_ndcg = ndcg(qid_result['docno'].to_list(), qid_test_set['docno'].to_list())\n",
    "    bm25_ndcgs[qid] = q_ndcg\n",
    "    print('qid {}: {}'.format(qid, q_ndcg))\n",
    "    \n",
    "print('ndcg: {}'.format(sum(bm25_ndcgs.values()) / len(bm25_ndcgs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate for random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qid 0: 0\n",
      "qid 1: 0.31546487678572877\n",
      "qid 2: 0.3010299956639812\n",
      "qid 3: 0.36996350175891385\n",
      "qid 4: 0.25\n",
      "qid 5: 0.38685280723454163\n",
      "qid 6: 0.3617152762344296\n",
      "qid 7: 0.31601601731991863\n",
      "qid 8: 0.3075452067542794\n",
      "qid 9: 0\n",
      "qid 10: 0\n",
      "qid 11: 0.5368596003428795\n",
      "qid 12: 0.25\n",
      "qid 13: 0.31546487678572877\n",
      "qid 14: 0\n",
      "qid 15: 0.23137821315975915\n",
      "qid 16: 1.0\n",
      "qid 17: 0\n",
      "qid 18: 0.2626495350371935\n",
      "qid 19: 0.38685280723454163\n",
      "qid 20: 0.5992429307166866\n",
      "qid 21: 0\n",
      "qid 22: 0\n",
      "qid 23: 0\n",
      "qid 24: 0.23137821315975915\n",
      "qid 25: 0\n",
      "qid 26: 0\n",
      "qid 27: 0\n",
      "qid 28: 0.23137821315975915\n",
      "qid 29: 0.24465054211822604\n",
      "ndcg: 0.22994808711554424\n"
     ]
    }
   ],
   "source": [
    "qids = range(30)\n",
    "r_ndcgs = {qid: 0 for qid in qids}\n",
    "for qid in qids:\n",
    "    qid_test_set = test_set[test_set['qid'] == qid]\n",
    "    qid_result = np.random.choice(8255, 20, replace=False).astype(int)\n",
    "    q_ndcg = ndcg(qid_result, qid_test_set['docno'].to_list())\n",
    "    r_ndcgs[qid] = q_ndcg\n",
    "    print('qid {}: {}'.format(qid, q_ndcg))\n",
    "    \n",
    "print('ndcg: {}'.format(sum(r_ndcgs.values()) / len(r_ndcgs)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8a7ad60629c7992fdadfcbec1ee9d18d5ed6e222b8ad46df459875a57fae42b2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
