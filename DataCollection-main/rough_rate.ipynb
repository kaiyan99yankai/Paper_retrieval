{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rate the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_df = pd.read_csv('./data/gs_results.csv')\n",
    "gs_df['title'] = gs_df['title'].str.casefold()\n",
    "pc_df = pd.read_csv('./data/pc_results.csv')\n",
    "pc_df['title'] = pc_df['title'].str.casefold()\n",
    "ss_df = pd.read_csv('./data/ss_results.csv')\n",
    "ss_df['title'] = ss_df['title'].str.casefold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIER1 = 40\n",
    "TIER2 = 100\n",
    "TIER3 = 200\n",
    "gs_rate_df = gs_df[['area','rank','title']][gs_df['rank']<=200].copy()\n",
    "pc_rate_df = pc_df.copy()\n",
    "ss_rate_df = ss_df[['area','rank','title']].copy()\n",
    "gs_rate_df['rate'] = gs_rate_df['rank'].apply(lambda x: 5 if x<=TIER1 else 4 if x<=TIER2 else 3 if x<=TIER3 else 2)\n",
    "pc_rate_df['rate'] = pc_rate_df['rank'].apply(lambda x: 5 if x<=TIER1 else 4 if x<=TIER2 else 3)\n",
    "ss_rate_df['rate'] = ss_rate_df['rank'].apply(lambda x: 5 if x<=TIER1 else 4 if x<=TIER2 else 3)\n",
    "\n",
    "rate_df = gs_rate_df.merge(pc_rate_df, on=['area', 'title'], how='outer', suffixes=('_gs', '_pc'))\n",
    "rate_df = rate_df.merge(ss_rate_df, on=['area', 'title'], how='outer')\n",
    "rate_df.rename(columns={'rank': 'rank_ss', 'rate': 'rate_ss'}, inplace=True)\n",
    "rate_df['rate_ss'].fillna(1, inplace=True)\n",
    "rate_df['rank_ss'].fillna(201, inplace=True)\n",
    "rate_df['rate_pc'].fillna(1, inplace=True)\n",
    "rate_df['rank_pc'].fillna(201, inplace=True)\n",
    "rate_df['rate_gs'].fillna(1, inplace=True)\n",
    "rate_df['rank_gs'].fillna(401, inplace=True)\n",
    "\n",
    "rate_df['agg_rate'] = (rate_df['rate_gs']*0.3 + rate_df['rate_pc']*0.4 + rate_df['rate_ss']*0.3)\n",
    "rate_df['agg_rank'] = (rate_df['rank_gs']*0.3 + rate_df['rank_pc']*0.4 + rate_df['rank_ss']*0.3)\n",
    "rate_df = rate_df.sort_values(by=['area', 'agg_rate', 'agg_rank'], ascending=[True, False, True]).reset_index(drop=True)\n",
    "rate_df['rank'] = rate_df.groupby('area').cumcount()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the total dataframe that contains download information and the pdf link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = rate_df.merge(gs_df[['area', 'title', 'pdf_link']], on=['area', 'title'], how='left')\n",
    "total_df = total_df.merge(ss_df[['area', 'title', 'abstract', 'citationCount', 'referenceCount', 'influentialCitationCount', 'fieldsOfStudy']], on=['area', 'title'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df['pdf_link'].fillna('', inplace=True)\n",
    "total_df['abstract'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_idx = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "lack_info_df = total_df[total_df['abstract'] == ''].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 27/71 [00:10<00:14,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internal Server Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 29/71 [02:11<17:54, 25.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internal Server Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 37/71 [04:15<02:46,  4.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internal Server Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [06:36<00:00,  5.58s/it]\n"
     ]
    }
   ],
   "source": [
    "lack_info_df.drop(drop_idx, inplace=True)\n",
    "drop_idx = []\n",
    "for idx, paper in tqdm(lack_info_df.iterrows(), total=lack_info_df.shape[0]):\n",
    "    if paper['abstract'] == '':\n",
    "        title_formatted = paper['title'].replace(' ', '+')\n",
    "        data = requests.get(f'https://api.semanticscholar.org/graph/v1/paper/search?query={title_formatted}&limit=1&fields=abstract,referenceCount,citationCount,influentialCitationCount').json()\n",
    "        if data.get('message') is not None:\n",
    "            lack_info_df = total_df[total_df['abstract'] == '']\n",
    "            print(data.get('message'))\n",
    "            time.sleep(120)\n",
    "        else:\n",
    "            data = data.get('data')\n",
    "            if data:\n",
    "                data = data[0]\n",
    "                paper['abstract'] = data.get('abstract')\n",
    "                paper['citationCount'] = data.get('citationCount')\n",
    "                paper['referenceCount'] = data.get('referenceCount')\n",
    "                paper['influentialCitationCount'] = data.get('influentialCitationCount')\n",
    "            else:\n",
    "                drop_idx.append(idx)\n",
    "    total_df.loc[idx] = paper\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(total_df['abstract'] == '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.to_csv('./data/total_info_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = total_df[total_df['rank'] <= 100].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3024/3024 [02:33<00:00, 19.72it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx, paper in tqdm(test_df.iterrows(), total=test_df.shape[0]):\n",
    "    if paper['abstract'] == '':\n",
    "        title_formatted = paper['title'].replace(' ', '+')\n",
    "        data = requests.get(f'https://api.semanticscholar.org/graph/v1/paper/search?query={title_formatted}&limit=1&fields=abstract,referenceCount,citationCount,influentialCitationCount').json()\n",
    "        if data.get('message') is not None:\n",
    "            print(data.get('message'))\n",
    "            break\n",
    "        else:\n",
    "            data = data.get('data')\n",
    "            if data:\n",
    "                data = data[0]\n",
    "                paper['abstract'] = data.get('abstract')\n",
    "                paper['citationCount'] = data.get('citationCount')\n",
    "                paper['referenceCount'] = data.get('referenceCount')\n",
    "                paper['influentialCitationCount'] = data.get('influentialCitationCount')\n",
    "    test_df.loc[idx] = paper\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['abstract'].fillna('', inplace=True)\n",
    "sum(test_df['abstract'] == '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.loc[8080, 'title'] = 'An Aerial Weed Detection System for Green Onion Crops Using the You-Only-Look- Once (YOLO) Deep Learning Algorithm'.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.loc[8080, 'abstract'] = 'Herbicide application is a common and inevitable method for preventing weed growth for some crops. Green onions are vulnerable to and significantly affected by weed infestation. However, herbicide contamination can pose as a food safety concern, especially in Japanese cuisine where green onions are typically eaten fresh. As a possible solution, an herbicide spraying system precisely targeting weeds while avoiding green onions was conceptualized. As a preliminary investigation, this study develops and evaluates the performance of what is referred to as the YOLO-WEED, a system that allows the smart detection of weeds through the utilization of unmanned aerial vehicles (UAVs) combined with You-Only-Look-Once (YOLO) deep learning algorithm. YOLO is a forerunner in terms of inference time in object detection, making it suitable for UAV applications. For the dataset, a five-minute UAV video was taken at altitude 4-5 meters at 0-1.3 m/s speed. Each frame from the UAV video were captured and cropped into tiles. 600 of these tiles were selected, annotated and split into training and validation dataset (450) and testing (150). After that, training, validation and testing were performed on YOLO-WEED with the GPU NVIDIA GeForce GTX 1060. IoU, which is the ratio between area of overlap and area of union of the bounding boxes of the ground truth object and the prediction, is the basis of true positive (TP), false positive (FP) and false negative (FN). Based on the TP, FP and FN, the following main performance metrics can be calculated: F1 score (with values 0 to 1) and mean average precision (with values 0 to 100 % with a threshold of 50% for IoU). Moreover, the detection speed expressed in frame per second (FPS) was also determined. YOLO-WEED demonstrated high detection speed (23.7 to 27.8 FPS) and remarkable performance, with mean average precision of 91.09 % and an F1 score of 0.85. YOLO-WEED was also tested on a cropped UAV video and the limitation of YOLO in detecting small objects was minimized. These results successfully show the effectiveness of the YOLO-WEED system for real-time UAV weed detection given its high speed and high accuracy in detection.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('./data/test_set.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98ab6bb59f86b054a55de3821f32cbbb81650a75d3a80945573196de73c4c46c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
